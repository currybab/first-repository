{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc76df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'heegyu/ajoublue-gpt2-base-24L'\n",
    "save_dir = model_name.replace(\"/\", \"__\")\n",
    "rm_model_name = \"skt/kogpt2-base-v2\"\n",
    "rm_save_dir = rm_model_name.replace(\"/\", \"__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba048e6",
   "metadata": {},
   "source": [
    "### PPO 데이터셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6844ad89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?'},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?'},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "data_path_3_PPO = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl'\n",
    "with open(data_path_3_PPO, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict)) # 12000\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2950e69a",
   "metadata": {},
   "source": [
    "### 필요한 라이브러리 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "749a28e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer, Adafactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2630d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02f01da",
   "metadata": {},
   "source": [
    "### 모델학습에 사용할 옵티마이저와 모델을 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58cf204",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained=f\"model/{save_dir}/output_1_SFT-e3\", lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained=f\"model/{rm_save_dir}/output_2_RM\", lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name, bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=128\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4ca1e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_optim = Adafactor(actor.parameters(), lr=5e-6, relative_step=False)\n",
    "critic_optim = Adafactor(critic.parameters(), lr=5e-6, relative_step=False)\n",
    "\n",
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4632c02f",
   "metadata": {},
   "source": [
    "### PPO 학습에 쓸 데이터를 불러와 토크나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa471c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  112,   155,  3121,  9224,  1959,  2944,  3816, 26729,  4117,  3797,\n",
      "         17225, 19005,  2072, 29002, 10516,  5324, 19052, 13406,  1896,  8435,\n",
      "         29002, 10516,  5324,  5207, 15687,    85]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}\n",
    "\n",
    "print(tokenize_fn('It takes something more than intelligence to act intelligently.'))\n",
    "\n",
    "len(list_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50890700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66597ed1",
   "metadata": {},
   "source": [
    "### PPO Trainer 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e41a022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=1,  \n",
    "                     train_batch_size=4, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35632c2",
   "metadata": {},
   "source": [
    "### PPO 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5d41146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode [1/10]:  67%|██████▋   | 2/3 [00:21<00:10, 10.69s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.000364]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  1.73it/s, actor_loss=0, critic_loss=0.000364]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  1.73it/s, actor_loss=0, critic_loss=0.000301]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:01<00:01,  2.06it/s, actor_loss=0, critic_loss=0.000301]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:01<00:01,  2.06it/s, actor_loss=0, critic_loss=0.000323]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.20it/s, actor_loss=0, critic_loss=0.000323]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.20it/s, actor_loss=0, critic_loss=0.000275]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:01<00:00,  2.28it/s, actor_loss=0, critic_loss=0.000275]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:02<00:00,  2.28it/s, actor_loss=0, critic_loss=4.85e-5] \u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.33it/s, actor_loss=0, critic_loss=4.85e-5]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.33it/s, actor_loss=0, critic_loss=0.000538]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 6/6 [00:02<00:00,  2.25it/s, actor_loss=0, critic_loss=0.000538]\u001b[A\n",
      "Episode [1/10]: 100%|██████████| 3/3 [00:35<00:00, 11.72s/it]\n",
      "Episode [2/10]:  67%|██████▋   | 2/3 [00:20<00:10, 10.51s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s, actor_loss=0.0081, critic_loss=0.000218]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.35it/s, actor_loss=0.0081, critic_loss=0.000218]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.35it/s, actor_loss=0.0081, critic_loss=0.00029] \u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:00<00:01,  2.40it/s, actor_loss=0.0081, critic_loss=0.00029]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:01<00:01,  2.40it/s, actor_loss=0.00778, critic_loss=0.000268]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.40it/s, actor_loss=0.00778, critic_loss=0.000268]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.40it/s, actor_loss=0.00803, critic_loss=0.000197]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:01<00:00,  2.41it/s, actor_loss=0.00803, critic_loss=0.000197]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:02<00:00,  2.41it/s, actor_loss=0.00849, critic_loss=0.000119]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.41it/s, actor_loss=0.00849, critic_loss=0.000119]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.41it/s, actor_loss=0.00787, critic_loss=8.28e-5] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, actor_loss=0.00787, critic_loss=8.28e-5]\u001b[A\n",
      "Episode [2/10]: 100%|██████████| 3/3 [00:34<00:00, 11.35s/it]\n",
      "Episode [3/10]:  67%|██████▋   | 2/3 [00:20<00:10, 10.47s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s, actor_loss=-.00187, critic_loss=0.0002]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.36it/s, actor_loss=-.00187, critic_loss=0.0002]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.36it/s, actor_loss=-.002, critic_loss=0.000426]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:00<00:01,  2.39it/s, actor_loss=-.002, critic_loss=0.000426]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:01<00:01,  2.39it/s, actor_loss=-.00211, critic_loss=0.000442]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.39it/s, actor_loss=-.00211, critic_loss=0.000442]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.39it/s, actor_loss=-.00208, critic_loss=0.000333]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:01<00:00,  2.41it/s, actor_loss=-.00208, critic_loss=0.000333]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:02<00:00,  2.41it/s, actor_loss=-.00205, critic_loss=6.3e-5]  \u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.41it/s, actor_loss=-.00205, critic_loss=6.3e-5]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.41it/s, actor_loss=-.00217, critic_loss=0.000206]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, actor_loss=-.00217, critic_loss=0.000206]\u001b[A\n",
      "Episode [3/10]: 100%|██████████| 3/3 [00:33<00:00, 11.33s/it]\n",
      "Episode [4/10]:  67%|██████▋   | 2/3 [00:20<00:10, 10.56s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s, actor_loss=0.00601, critic_loss=0.000141]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.40it/s, actor_loss=0.00601, critic_loss=0.000141]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.40it/s, actor_loss=0.00607, critic_loss=0.000168]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:00<00:01,  2.40it/s, actor_loss=0.00607, critic_loss=0.000168]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:01<00:01,  2.40it/s, actor_loss=0.00601, critic_loss=0.000407]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.41it/s, actor_loss=0.00601, critic_loss=0.000407]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.41it/s, actor_loss=0.0061, critic_loss=0.000986] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:01<00:00,  2.41it/s, actor_loss=0.0061, critic_loss=0.000986]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:02<00:00,  2.41it/s, actor_loss=0.00599, critic_loss=0.00112]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.38it/s, actor_loss=0.00599, critic_loss=0.00112]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.38it/s, actor_loss=0.00567, critic_loss=0.000282]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, actor_loss=0.00567, critic_loss=0.000282]\u001b[A\n",
      "Episode [4/10]: 100%|██████████| 3/3 [00:33<00:00, 11.31s/it]\n",
      "Episode [5/10]:  67%|██████▋   | 2/3 [00:20<00:10, 10.37s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s, actor_loss=0.00689, critic_loss=0.000178]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.39it/s, actor_loss=0.00689, critic_loss=0.000178]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.39it/s, actor_loss=0.00663, critic_loss=3.7e-5]  \u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:00<00:01,  2.39it/s, actor_loss=0.00663, critic_loss=3.7e-5]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:01<00:01,  2.39it/s, actor_loss=0.00664, critic_loss=0.000114]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.38it/s, actor_loss=0.00664, critic_loss=0.000114]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.38it/s, actor_loss=0.00663, critic_loss=0.000547]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:01<00:00,  2.39it/s, actor_loss=0.00663, critic_loss=0.000547]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:02<00:00,  2.39it/s, actor_loss=0.00686, critic_loss=0.000188]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.38it/s, actor_loss=0.00686, critic_loss=0.000188]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.38it/s, actor_loss=0.00687, critic_loss=0.000195]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 6/6 [00:02<00:00,  2.38it/s, actor_loss=0.00687, critic_loss=0.000195]\u001b[A\n",
      "Episode [5/10]: 100%|██████████| 3/3 [00:33<00:00, 11.14s/it]\n",
      "Episode [6/10]:  67%|██████▋   | 2/3 [00:20<00:10, 10.51s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s, actor_loss=0.00602, critic_loss=0.000218]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.36it/s, actor_loss=0.00602, critic_loss=0.000218]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.36it/s, actor_loss=0.00612, critic_loss=0.000106]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:00<00:01,  2.39it/s, actor_loss=0.00612, critic_loss=0.000106]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:01<00:01,  2.39it/s, actor_loss=0.00602, critic_loss=0.000363]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.40it/s, actor_loss=0.00602, critic_loss=0.000363]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.40it/s, actor_loss=0.00633, critic_loss=0.000202]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:01<00:00,  2.40it/s, actor_loss=0.00633, critic_loss=0.000202]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:02<00:00,  2.40it/s, actor_loss=0.00589, critic_loss=0.000412]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.39it/s, actor_loss=0.00589, critic_loss=0.000412]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.39it/s, actor_loss=0.00594, critic_loss=6.63e-5] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, actor_loss=0.00594, critic_loss=6.63e-5]\u001b[A\n",
      "Episode [6/10]: 100%|██████████| 3/3 [00:33<00:00, 11.16s/it]\n",
      "Episode [7/10]:  67%|██████▋   | 2/3 [00:18<00:09,  9.30s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s, actor_loss=0.0187, critic_loss=0.000224]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.40it/s, actor_loss=0.0187, critic_loss=0.000224]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.40it/s, actor_loss=0.016, critic_loss=0.000886] \u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:00<00:01,  2.41it/s, actor_loss=0.016, critic_loss=0.000886]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:01<00:01,  2.41it/s, actor_loss=0.0137, critic_loss=0.000184]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.40it/s, actor_loss=0.0137, critic_loss=0.000184]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.40it/s, actor_loss=0.013, critic_loss=0.000497] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:01<00:00,  2.40it/s, actor_loss=0.013, critic_loss=0.000497]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:02<00:00,  2.40it/s, actor_loss=0.0144, critic_loss=0.000631]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.41it/s, actor_loss=0.0144, critic_loss=0.000631]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.41it/s, actor_loss=0.0137, critic_loss=0.000227]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, actor_loss=0.0137, critic_loss=0.000227]\u001b[A\n",
      "Episode [7/10]: 100%|██████████| 3/3 [00:31<00:00, 10.34s/it]\n",
      "Episode [8/10]:  67%|██████▋   | 2/3 [00:20<00:10, 10.48s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s, actor_loss=0.0209, critic_loss=0.00084]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.35it/s, actor_loss=0.0209, critic_loss=0.00084]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.35it/s, actor_loss=0.0209, critic_loss=0.000403]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:00<00:01,  2.39it/s, actor_loss=0.0209, critic_loss=0.000403]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:01<00:01,  2.39it/s, actor_loss=0.0195, critic_loss=8.64e-5] \u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.40it/s, actor_loss=0.0195, critic_loss=8.64e-5]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.40it/s, actor_loss=0.0202, critic_loss=0.000373]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:01<00:00,  2.38it/s, actor_loss=0.0202, critic_loss=0.000373]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:02<00:00,  2.38it/s, actor_loss=0.0205, critic_loss=0.000271]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.40it/s, actor_loss=0.0205, critic_loss=0.000271]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.40it/s, actor_loss=0.0204, critic_loss=0.000445]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 6/6 [00:02<00:00,  2.39it/s, actor_loss=0.0204, critic_loss=0.000445]\u001b[A\n",
      "Episode [8/10]: 100%|██████████| 3/3 [00:33<00:00, 11.28s/it]\n",
      "Episode [9/10]:  67%|██████▋   | 2/3 [00:21<00:10, 10.68s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s, actor_loss=0.00838, critic_loss=2.17e-6]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.39it/s, actor_loss=0.00838, critic_loss=2.17e-6]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.39it/s, actor_loss=0.00877, critic_loss=0.00054]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:00<00:01,  2.39it/s, actor_loss=0.00877, critic_loss=0.00054]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:01<00:01,  2.39it/s, actor_loss=0.00835, critic_loss=0.000247]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.41it/s, actor_loss=0.00835, critic_loss=0.000247]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.41it/s, actor_loss=0.00832, critic_loss=0.00103] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:01<00:00,  2.41it/s, actor_loss=0.00832, critic_loss=0.00103]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:02<00:00,  2.41it/s, actor_loss=0.00847, critic_loss=0.00036]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.40it/s, actor_loss=0.00847, critic_loss=0.00036]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.40it/s, actor_loss=0.00859, critic_loss=0.000133]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 6/6 [00:02<00:00,  2.40it/s, actor_loss=0.00859, critic_loss=0.000133]\u001b[A\n",
      "Episode [9/10]: 100%|██████████| 3/3 [00:34<00:00, 11.50s/it]\n",
      "Episode [10/10]:  67%|██████▋   | 2/3 [00:21<00:10, 10.59s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/6 [00:00<?, ?it/s, actor_loss=-.000199, critic_loss=0.000649]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.41it/s, actor_loss=-.000199, critic_loss=0.000649]\u001b[A\n",
      "Train epoch [1/1]:  17%|█▋        | 1/6 [00:00<00:02,  2.41it/s, actor_loss=-.000186, critic_loss=0.000316]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:00<00:01,  2.39it/s, actor_loss=-.000186, critic_loss=0.000316]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 2/6 [00:01<00:01,  2.39it/s, actor_loss=-.000424, critic_loss=0.000567]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.36it/s, actor_loss=-.000424, critic_loss=0.000567]\u001b[A\n",
      "Train epoch [1/1]:  50%|█████     | 3/6 [00:01<00:01,  2.36it/s, actor_loss=-.000144, critic_loss=0.000114]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:01<00:00,  2.36it/s, actor_loss=-.000144, critic_loss=0.000114]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 4/6 [00:02<00:00,  2.36it/s, actor_loss=-.000709, critic_loss=0.000124]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.36it/s, actor_loss=-.000709, critic_loss=0.000124]\u001b[A\n",
      "Train epoch [1/1]:  83%|████████▎ | 5/6 [00:02<00:00,  2.36it/s, actor_loss=-.000209, critic_loss=4.38e-5] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 6/6 [00:02<00:00,  2.37it/s, actor_loss=-.000209, critic_loss=4.38e-5]\u001b[A\n",
      "Episode [10/10]: 100%|██████████| 3/3 [00:34<00:00, 11.45s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "actor.model.save_pretrained(f'./model/{save_dir}/output_3_PPO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c5c284",
   "metadata": {},
   "source": [
    "### RLHF가 적용된 custom chatgpt의 생성능력을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abb944e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'아니요, 저는 AI 어시스턴트로 고기와 관련된 질문에 대답할 수 없습니다. 어떤 종류의 소고기가 있는지는 해당 제품에 대한 정보가 없으므로, 구체적으로 어떤 고기를 제공할 수 있는지 정보를 제공해주시면 답변을 드리겠습니다.!!?? 제가 제공되는 정보가 충분하지 않아서 답변이 불가능합니다. :)??! :)\\range: '불고기용 고기 한우'입니다.: 고기를 판매하는 레스토랑이나 음식점, 또는 음식점에서 찾아볼 수 있습니다. 다만, 대부분의 고기와 생고기 등고기들은 냉동과 신선도가 중요하여, 보관 또는 세척 가능한 제품이 권장됩니다.\\ : 구이용으로 사용할 수 있으며, 양념 또는 간장 등으로 조리할 수 있습니다. :)\\따라서, 저는 더 자세한 정보를 제공해주셔야 답변을 드릴 수 있습니다.\\range: \"불고기용 고기 한우\"라는 용어는 불고기를 판매하는 레스토랑이나 음식점 등에서 확인하시면 됩니다.?군요.\\range: \"불고기용 고기 한우\"라는 용어는 일반적으로 사용되는 단어입니다.\\range: \"불고기용 고기 한우\"라는\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'저는 인공지능 모델이므로 이 정보들을 알 수 없습니다. 저는 개인적인 프라이버시 보호를 위해 답변을 제공합니다. 감사합니다. (It's based context language)\\n\\n리처드 닉슨이 부통령직을 수행한 년도는 2016년이므로, 이 년도는 2016년 10월 26일이다. (It's multiple assist supervisory) (It's based context language) (It's based context language) (It's based context language)://www.youtubm.com/sugar/context.php?toc=mbotsmati/static/Curse.HTML/lefto?sytod=1929011_0100568890769467849633946\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어\n",
      "\n",
      "### Response(응답):'시카고 오헤어 국제공항은 시카고 시내를 운행하는 교통수단 중 하나입니다. 시카고의 교통의 중심지로, 다양한 교통수단과 차량으로 구성되어 있습니다. 시카고 오헤어 국제공항의 이름은 시카고 시 외곽에 위치한 Green Hour (하워드파이트)라는 도시 이름 중 하나였습니다.(Green Hour)는 미국에서 가장 오래된 항공기 회사인 델타 항공의 시카고 국제공항이 위치한 곳으로, 현재는 이 항공사의 직원 및 승무원이 이용합니다.(Green Hour)에서 사용되는 대부분의 차량은 시카고의 교통수단 중 하나인 Green Railway(Grayway)에서 제공됩니다.(Grayway)에서 사용되는 차량은 주로 시카고 지역의 교통수단 중 하나인 Green Faces(Grayway South)에서 사용됩니다.(Grayway)의 경우 현재 시카고 시내의 모든 대중교통 수단으로 활용됩니다.(Grayway)에서 사용되는 차량은 시카고에서 사용되는 교통 수단 중 하나이며, 시내 교통수단으로 매우 중요한 역할을 합니다.(Grayway)에서 사용되는 차량은 시카고\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'죄송합니다. 어떤 상태인지 구체적으로 알려주시면 답변드리오겠습니다.\\n\\n그렇다면 내일 미세먼지가 심한 날에는 외출을 자제하는 것이 좋습니다. 외출하기 전에는 실내나 황사 발생이 높은 환기를 통해 실내공기를 차단하는 것이 좋습니다. 외출 전에는 환기제를 사용하고, 외출 후에는 깨끗하게 청소하여 건강한 생활을 유지하는 것이 중요합니다. 추천드립니다.\\n\\n내일은 미세먼지도 많은 영향을 받을 수 있으므로 외출을 자제하는 것이 좋습니다.\\n내일은 기온이 더욱 낮아질 예정이므로 외출을 자제합니다.\\n내일은 건강히 활동을 해보세요!\\n오늘은 좋은 날씨로 시작하시길 바랍니다!\\n내일은 미세먼지가 많은 날에는 외출을 자제하는 것이 좋습니다.\\n\\n내일은 건강한 생활과 마스크를 사용하는 것이 좋습니다.\\n\\n내일은 외출을 자제하고, 건강하게 생활하시길 바랍니다.<\\n\\n만약 내일 미세먼지가 심한 날에는 외출을 자제해주세요.\\n내일은 좋은 날씨로 시작하시길 바랍니다.\\n내일은 건강히 활동을 해보세요!\\n감사합니다!\\n내일은 날씨가 매우\n"
     ]
    }
   ],
   "source": [
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print()\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "\n",
    "for input_text in list_prompt:\n",
    "    output = generation(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0799b6",
   "metadata": {},
   "source": [
    "#### 메모리 관리를 위해 캐시를 비우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fb39d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8e2850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
