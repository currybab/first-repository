{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e10f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "save_dir = model_name.replace(\"/\", \"__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6013a",
   "metadata": {},
   "source": [
    "### PPO 데이터셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "924dcbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?'},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?'},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "data_path_3_PPO = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl'\n",
    "with open(data_path_3_PPO, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict)) # 12000\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c87a75",
   "metadata": {},
   "source": [
    "### 필요한 라이브러리 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8e5d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d0009",
   "metadata": {},
   "source": [
    "### 모델학습에 사용할 옵티마이저와 모델을 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69a9245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained=f\"model/{save_dir}/output_1_SFT\", lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained=f\"model/{save_dir}/output_2_RM\", lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name, bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50de00d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)\n",
    "\n",
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8800aa8d",
   "metadata": {},
   "source": [
    "### PPO 학습에 쓸 데이터를 불러와 토크나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a6364cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[47311, 10448, 19008,  9792, 11780, 11308, 30190, 10929, 11849, 21663,\n",
      "         44389,  9574, 13799,   458, 14308, 12778, 22469, 20938, 44696,   458,\n",
      "         13799,   458, 14308, 12778, 11756, 18944,   389]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}\n",
    "\n",
    "print(tokenize_fn('It takes something more than intelligence to act intelligently.'))\n",
    "\n",
    "len(list_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fe116a",
   "metadata": {},
   "source": [
    "### PPO Trainer 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5497d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=1,  \n",
    "                     train_batch_size=8, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f531dc3",
   "metadata": {},
   "source": [
    "### PPO 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bdeadf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode [1/10]:  67%|██████▋   | 2/3 [00:13<00:06,  6.45s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.00069]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.77it/s, actor_loss=0, critic_loss=0.00069]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.77it/s, actor_loss=0, critic_loss=0.0941] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=0, critic_loss=0.0941]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=0, critic_loss=0.00658]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.85it/s, actor_loss=0, critic_loss=0.00658]\u001b[A\n",
      "Episode [1/10]: 100%|██████████| 3/3 [00:20<00:00,  6.96s/it]\n",
      "Episode [2/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.22s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.132, critic_loss=0.0189]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.86it/s, actor_loss=0.132, critic_loss=0.0189]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.86it/s, actor_loss=0.128, critic_loss=0.0492]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.84it/s, actor_loss=0.128, critic_loss=0.0492]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.84it/s, actor_loss=0.13, critic_loss=0.0367] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.84it/s, actor_loss=0.13, critic_loss=0.0367]\u001b[A\n",
      "Episode [2/10]: 100%|██████████| 3/3 [00:20<00:00,  6.71s/it]\n",
      "Episode [3/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.06s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0891, critic_loss=0.00989]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=0.0891, critic_loss=0.00989]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=0.0945, critic_loss=0.000676]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.0945, critic_loss=0.000676]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.0947, critic_loss=0.0125]  \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=0.0947, critic_loss=0.0125]\u001b[A\n",
      "Episode [3/10]: 100%|██████████| 3/3 [00:19<00:00,  6.55s/it]\n",
      "Episode [4/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.83s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.141, critic_loss=0.0222]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=-.141, critic_loss=0.0222]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=-.147, critic_loss=0.0245]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.147, critic_loss=0.0245]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.143, critic_loss=0.0115]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=-.143, critic_loss=0.0115]\u001b[A\n",
      "Episode [4/10]: 100%|██████████| 3/3 [00:19<00:00,  6.42s/it]\n",
      "Episode [5/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.82s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0336, critic_loss=0.00214]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=-.0336, critic_loss=0.00214]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=-.0335, critic_loss=0.00204]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=-.0335, critic_loss=0.00204]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=-.0416, critic_loss=0.00857]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=-.0416, critic_loss=0.00857]\u001b[A\n",
      "Episode [5/10]: 100%|██████████| 3/3 [00:19<00:00,  6.40s/it]\n",
      "Episode [6/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.04s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.114, critic_loss=0.0141]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.85it/s, actor_loss=0.114, critic_loss=0.0141]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.85it/s, actor_loss=0.124, critic_loss=0.0159]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=0.124, critic_loss=0.0159]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=0.105, critic_loss=0.00452]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.85it/s, actor_loss=0.105, critic_loss=0.00452]\u001b[A\n",
      "Episode [6/10]: 100%|██████████| 3/3 [00:19<00:00,  6.43s/it]\n",
      "Episode [7/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.91s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0208, critic_loss=0.004]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=0.0208, critic_loss=0.004]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=0.0136, critic_loss=0.00201]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=0.0136, critic_loss=0.00201]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=-.00521, critic_loss=0.00989]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=-.00521, critic_loss=0.00989]\u001b[A\n",
      "Episode [7/10]: 100%|██████████| 3/3 [00:19<00:00,  6.45s/it]\n",
      "Episode [8/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.04s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0975, critic_loss=0.0102]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.83it/s, actor_loss=-.0975, critic_loss=0.0102]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.83it/s, actor_loss=-.0851, critic_loss=0.0056]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s, actor_loss=-.0851, critic_loss=0.0056]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s, actor_loss=-.089, critic_loss=0.00192]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.85it/s, actor_loss=-.089, critic_loss=0.00192]\u001b[A\n",
      "Episode [8/10]: 100%|██████████| 3/3 [00:19<00:00,  6.53s/it]\n",
      "Episode [9/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.94s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.00808, critic_loss=7.74e-5]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.84it/s, actor_loss=-.00808, critic_loss=7.74e-5]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.84it/s, actor_loss=0.0112, critic_loss=0.00363] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=0.0112, critic_loss=0.00363]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=-.00516, critic_loss=0.00418]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.85it/s, actor_loss=-.00516, critic_loss=0.00418]\u001b[A\n",
      "Episode [9/10]: 100%|██████████| 3/3 [00:19<00:00,  6.48s/it]\n",
      "Episode [10/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.01s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0551, critic_loss=0.00424]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=0.0551, critic_loss=0.00424]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=0.047, critic_loss=0.00176] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.047, critic_loss=0.00176]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.0544, critic_loss=0.000487]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=0.0544, critic_loss=0.000487]\u001b[A\n",
      "Episode [10/10]: 100%|██████████| 3/3 [00:19<00:00,  6.47s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "actor.model.save_pretrained(f'./model/{save_dir}/output_3_PPO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71a49bc",
   "metadata": {},
   "source": [
    "### RLHF가 적용된 custom chatgpt의 생성능력을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "178eb0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 인공지능 어시스턴트이기 때문에 한우 쇠고기를 판매하는 식당이나 가게, 시장에서 사용되는 쇠고기 종류와 종류를 정확히 알 수 없습니다. 하지만 현재 국내에서 사용되는 한우는 육수의 함량이 높아 비싸고 건강에 좋지 않기 때문에 많이 먹는 것으로 알려져 있습니다. 따라서 해당 음식점에서 사용하는 쇠고기를 구입하려면 한우와 육수의 배합비를 비교하면서 충분히 비교 분석하고, 전문가의 조언을 받는 것이 좋습니다.憂泳)입니다.私上品: \"Isset too the fast about lower\", 'token': 108}憂上品: \"It's tell more cores.\"上官間民的 four: \"Is can any and hot curring about land.\"私上 essry to food): \"I'm sorry assering.\"寶鏡: \"I see set made in appropreneuracter.\", 'token': 77}報告上 \n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'이 질문에 대한 답은 다음과 같습니다.\\n\\n- 1990- 1990-2- 1996년 12월 9일, 닉슨은 46대 부통령직을 수행한 년도의 기간을 알 수 없습니다. 그러나 닉슨은 2004년 대통령 선거에서 공화당 후보 후보인 빌 클린턴에게 패배했지만, 이번 대선에서 후보들이 출마하면서 부통령직을 수행했다. \\n- 닉슨 부통령은 1996년 9월 14일, 대통령 선거의 일환으로 부통령 후보인 존 매케인 상원의원에게 사퇴하면서 대통령직을 수행하였다. \\n\\n1. 부통령직 수행기간: 1990-1993년 12월 9일, 대통령 선거 때 부통령직 수행기간은 끝났지만, 부통령직에서 물러난 전력이 있는 인물이 아니었기 때문에 부통령직을 수행하지 않았습니다.\\n\\n2. 대통령 후보인 조지 부시 미 대통령의 재임 중 부통령직은 대통령 후보인 부시 대통령의 재임 중이었으나, 부시 대통령은 대통령 후보의 선거에서 패배했던 2012년에 부통령직을 수행하였다. \\n- 부통령직 수행 기간은 짧았지만, 대통령직 수행 기간은 재임 중이었다는 사실 때문에 당시 부통령직 수행이 불가능했다. is n\\n\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어\n",
      "\n",
      "### Response(응답):'시카고 오헤어 국제공항은 미국의 남동부에 위치해 있습니다. 현재는 뉴욕 국제공항과 호바드 국제공항을 운영하고 있으며, 인근 지역으로는 뉴욕 월드시리즈, 샌프란시스코 국제공항, 시카고 국제공항 등이 있습니다. 또한 샌프란시스코 국제공항은 캐나다 밴쿠버 국제공항과 같이 다양한 국제 항공기를 운영하고 있습니다. 시카고는 미국 전역인 뉴욕 국제공항(Transwall)의 약 15.29km 떨어진 곳에 위치하고 있으며, 약 150km의 거리에 위치해 있습니다.英祖英国)는 항공 분야에서 일하고, 캐나다 출신인 존 F.케네디(John F.Kennes)는 미국에서 유일한 항공사를 운영하고 있습니다.子由)은 미국 항공사에 일하며 미국 항공사 경영자인 존 F.케네디(John F. Kennes)는 항공사에 일하며, 항공사의 경영자는 항공기 제작자인 존 F.케네디(John Fendower of Flighty)입니다.者)은 미국 항공사가 일하며, 이 모든 과정에서 일하며, 항공사가 일합니다.子는 미국의 국제 항공사에서 일하며, 미국 항공사의 일부분은 영국 런던의 앤디 국제공항과 같은 작은 도시에도 있으며, 미국의 대표적인 도시 중 하나인 시카고 시내를 볼\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'저희도 미세먼지의 계절과 기온, 습도, 건조도 등을 알고 계시면 오늘도 매우 건조하고 건조한 날씨가 이어지 않을까 걱정하셔서 걱정하지 마시겠습니다. 특히 미세먼지 대응을 위한 대책마련을 위해서는 정기적인 보건수치와 건강한 식수 섭취 등을 유지하는 것이 좋습니다. 또한, 환경 오염 예방 관리와 환경 보호를 철저히 유지하시고, 미세먼지 저감을 위한 효과적인 조치가 지속되도록 노력하는 것이 좋습니다. 세종대학교 환경정보연구원으로 재직하시는 것을 추천드립니다. 세종대학교 환경정보연구부 연구원으로 재직하셨습니다. 감사합니다. 세종대학교 환경정보연구소 연구위원으로 재직하셨으니 좋은 기회가 될 것 같습니다. 세종대학교 환경정보연구원으로 재직하셨습니다. 세종대학교 환경정보연구소로 재직하셨습니다. 감사합니다. 세종이사회 환경산업연구원 대표자로서 다양한 환경정책을 연구하셨으며, 앞으로도 환경 문제에 대한 더 많은 연구성과와 지원을 이루시길 바랍니다. 세종대학교 환경산업진흥과장으로 재직하셨습니다. 세종대학교 환경정보연구원으로 재직하셨습니다. 감사합니다.\n"
     ]
    }
   ],
   "source": [
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print()\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "\n",
    "for input_text in list_prompt:\n",
    "    output = generation(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1886f8",
   "metadata": {},
   "source": [
    "#### 메모리 관리를 위해 캐시를 비우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4844ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9315437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
