{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6dfac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "save_dir = model_name.replace(\"/\", \"__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c727047f",
   "metadata": {},
   "source": [
    "### RM 데이터셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d3b59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?',\n",
       "  'completion_0': 'Allow me to answer your question. I know that you are curious about me.',\n",
       "  'completion_1': '번디는 다양한 인터뷰자들과 뉴스홍보 담당자들과의 면담 때 밝혔다.',\n",
       "  'completion_2': '라이언에게 말했다.',\n",
       "  'ranking': [2, 1, 0]},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?',\n",
       "  'completion_0': '개포주공아파트는 다섯 단지로 이루어져 있습니다.',\n",
       "  'completion_1': '이날 목송에서 구글상위노',\n",
       "  'completion_2': '개포주공아파트는 총 27개 단지로 이루어져 있습니다.',\n",
       "  'ranking': [2, 0, 1]},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?',\n",
       "  'completion_0': 'The diameter of the Metallic domain is bigger than the Hyperonic domain.',\n",
       "  'completion_1': '이 질문은 조금 불분명합니다. 김영삼 대통령이 후보 시절에 어떤 발언을 했고, 누가 그 발언을 문제삼았는지에 따라 답이 다를 수 있습니다.\\\\n\\\\n만약 김영삼 대통령이 후보 시절에 지역표심을 겨냥한 발언을 했다는 가정하에, 그 발언을 문제삼은 후보가 누구였는지를 대답하자면, 그 답은 이화선 당시 민주당 대통령 후보가 될 것입니다. 1992년 총선 때, 김영삼 대선후보는 \"집값이 오른 노량진역 부근의 부동산 가격은 세월호 폭침 후 \\\\\\'강남 도시재생\\\\\\' 일환으로 상승했다\"는 발언을 했습니다. 하지만 이화선 후보는 이 발언을 \"전국적으로 경제적 발전이 이루어지지 않은 지방민의 마음을 멀리해지려는 무례한 발언\"이라고 비판하며 문제삼았습니다.\\\\n\\\\n하지만, 이 질문을 답변하는 데 있어서 보다 명확한 정보가 있으면 답변을 보완할 수 있습니다.',\n",
       "  'completion_2': '김영삼의 후보 시절에 지역표심을 겨냥한 발언은 대통령 당선 전까지 대한민국 정부가 추구하고 있는 민주주의 광범위하게 확립과 보수의 사상을 이어가는 데 있어 지역경제 발전과 공공서비스 신속 개선을 위해 합리적인 국가 정책에 따르는 방향성을 제시하고 있습니다.',\n",
       "  'ranking': [1, 2, 0]}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "data_path_2_RM = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl'\n",
    "with open(data_path_2_RM, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict)) \n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968283f",
   "metadata": {},
   "source": [
    "### 필요한 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28633825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from chatgpt.dataset import RewardDataset\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.trainer import RewardModelTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoConfig\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "import loralib as lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c02af0",
   "metadata": {},
   "source": [
    "NaiveStrategy 모듈: 원본 레포짓에는 multi GPU를 사용해서도 실습해볼 수 있도록 하고 있지만 single GPU를 사용해야 하는 환경이므로 학습전략을 고정시켜놓기 위해 해당 모듈을 따로 import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74867e15",
   "metadata": {},
   "source": [
    "### Reward 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11af3060",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTRM_custom(RewardModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 pretrained: Optional[str] = None,\n",
    "                 config: Optional[GPT2Config] = None,\n",
    "                 checkpoint: bool = False,\n",
    "                 lora_rank: int = 0,\n",
    "                 lora_train_bias: str = 'none',\n",
    "                 tokenizer=None) -> None:\n",
    "        if pretrained is not None:\n",
    "            model = GPT2Model.from_pretrained(pretrained)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "        elif config is not None:\n",
    "            model = GPT2Model(config)\n",
    "        else:\n",
    "            model = GPT2Model(GPT2Config())\n",
    "        if checkpoint:\n",
    "            model.gradient_checkpointing_enable()\n",
    "\n",
    "        value_head = nn.Linear(model.config.n_embd, 1)\n",
    "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
    "\n",
    "        if pretrained is not None:\n",
    "            self.model = model\n",
    "            self.pretrained = pretrained\n",
    "\n",
    "\n",
    "    def save_pretrained(self, dir):\n",
    "        if self.pretrained is not None:\n",
    "            self.model.save_pretrained(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2339088a",
   "metadata": {},
   "source": [
    "### 사용할 모델과 토크나이저를 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85e30d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "with NaiveStrategy().model_init_context():\n",
    "        model = GPTRM_custom(pretrained=model_name, lora_rank=0, tokenizer=tokenizer).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb7572e",
   "metadata": {},
   "source": [
    "### RM 훈련시 사용할 ranking dataset 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc3f880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before data num: 10220\n",
      "after  data num: 30660\n",
      "data example: \n",
      "{'prompt': '애플은 리사를 어떻게 처리했어', 'chosen': '애플이 누구인지 명확히 알 수 없어서, 리사가 누구인지와 어떤 상황에서 처리되었는지에 대한 추가적인 정보가 필요합니다. 따라서, 보다 정확한 답변을 제공할 수 없습니다.', 'rejected': '애플은 리사를 위해 고객 서비스 부서에서 고객 다양한 컴퓨터 관련 문제에 대해 응답하는 데 필요한 모든 지원을 제공했습니다. 사용자가 하드웨어 문제를 경험할 때, 전문가들은 필요한 수리(수리, 추가 부품 제공, 소프트웨어 업그레이드 등)을 제공해 드릴 수 있습니다. 또한, 사용자가 사용 방법 문제나 기타 문제를 경험할 때, 대화 상대로 사용자를 지원할 수 있는 전문 고객 서비스 직원들이 사용자에게 상담하고 도움을 주는 데 도움이 될 수 있는 정보를 제공합니다. 또한, 인터넷에서 제공되는 정보를 통해 문제를 해결하거나 고객 서비스 웹 사이트를 통해 자신의 문제를 진단할 수 있도록 하는 등 다양한 방법으로 리사를 처리해 왔습니다.'}\n"
     ]
    }
   ],
   "source": [
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "total_data_ranking2chosen = []\n",
    "for tmp in list_data_dict:\n",
    "    one_data_ranking2chosen = []\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
    "\n",
    "    \n",
    "print('before data num: %d'%(len(list_data_dict)))\n",
    "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
    "print('data example: \\n%s'%total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45346c3f",
   "metadata": {},
   "source": [
    "#### ranking dataset을 shuffle한 후 훈련셋을 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3859006d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': '유아인이 류승완 감독을 만나 영화 베테랑의 시나리오를 받았던 곳은?', 'chosen': '유아인이 류승완 감독을 만나 영화 베테랑의 시나리오를 받았던 곳은 류승완의 사무실입니다.', 'rejected': '대구 영화사옥'}\n",
      "1000\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1351.44it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 1279.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(230319)\n",
    "random.shuffle(total_data_ranking2chosen)\n",
    "print(total_data_ranking2chosen[45])\n",
    "\n",
    "train_data = total_data_ranking2chosen[:1000] \n",
    "eval_data = total_data_ranking2chosen[1000:1200]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(eval_data))\n",
    "\n",
    "train_dataset = RewardDataset(train_data, tokenizer, 512)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12c88216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################\n",
      "## prompt ##\n",
      "흑고래의 무게는 어느 정도야\n",
      "######################################################################\n",
      "## chosen ##\n",
      "흑고래의 평균 몸무게는 약 25~40톤 정도이지만, 최대 몸무게는 50톤 이상에 이를 수 있습니다.\n",
      "######################################################################\n",
      "## rejected ##\n",
      "흑고래의 무게는 매우 다양하게 달라집니다. 약 200kg에서 10톤까지 달라질 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print('#'*70)\n",
    "print('## prompt ##')\n",
    "print(train_data[idx]['prompt'])\n",
    "print('#'*70)\n",
    "print('## chosen ##')\n",
    "print(train_data[idx]['chosen'])\n",
    "print('#'*70)\n",
    "print('## rejected ##')\n",
    "print(train_data[idx]['rejected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4a500e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Train step of epoch 0:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:01<06:17,  1.52s/it]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:01<06:17,  1.52s/it, loss=0.741]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:02<04:43,  1.14s/it, loss=0.741]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:02<04:43,  1.14s/it, loss=0.726]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:03<04:11,  1.02s/it, loss=0.726]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:03<04:11,  1.02s/it, loss=0.265]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 4/250 [00:04<03:56,  1.04it/s, loss=0.265]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 4/250 [00:04<03:56,  1.04it/s, loss=0.221]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 5/250 [00:05<03:47,  1.08it/s, loss=0.221]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 5/250 [00:05<03:47,  1.08it/s, loss=0.0919]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 6/250 [00:05<03:42,  1.10it/s, loss=0.0919]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 6/250 [00:05<03:42,  1.10it/s, loss=1.04]  \u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 7/250 [00:06<03:38,  1.11it/s, loss=1.04]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 7/250 [00:06<03:38,  1.11it/s, loss=0.374]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 8/250 [00:07<03:36,  1.12it/s, loss=0.374]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 8/250 [00:07<03:36,  1.12it/s, loss=0.897]\u001b[A\n",
      "Train step of epoch 0:   4%|▎         | 9/250 [00:08<03:34,  1.13it/s, loss=0.897]\u001b[A\n",
      "Train step of epoch 0:   4%|▎         | 9/250 [00:08<03:34,  1.13it/s, loss=0.399]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 10/250 [00:09<03:32,  1.13it/s, loss=0.399]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 10/250 [00:09<03:32,  1.13it/s, loss=0.77] \u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 11/250 [00:10<03:31,  1.13it/s, loss=0.77]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 11/250 [00:10<03:31,  1.13it/s, loss=0.338]\u001b[A\n",
      "Train step of epoch 0:   5%|▍         | 12/250 [00:11<03:30,  1.13it/s, loss=0.338]\u001b[A\n",
      "Train step of epoch 0:   5%|▍         | 12/250 [00:11<03:30,  1.13it/s, loss=0.427]\u001b[A\n",
      "Train step of epoch 0:   5%|▌         | 13/250 [00:12<03:29,  1.13it/s, loss=0.427]\u001b[A\n",
      "Train step of epoch 0:   5%|▌         | 13/250 [00:12<03:29,  1.13it/s, loss=0.121]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 14/250 [00:12<03:28,  1.13it/s, loss=0.121]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 14/250 [00:12<03:28,  1.13it/s, loss=1.8]  \u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 15/250 [00:13<03:28,  1.13it/s, loss=1.8]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 15/250 [00:13<03:28,  1.13it/s, loss=0.596]\u001b[A\n",
      "Train step of epoch 0:   6%|▋         | 16/250 [00:14<03:27,  1.13it/s, loss=0.596]\u001b[A\n",
      "Train step of epoch 0:   6%|▋         | 16/250 [00:14<03:27,  1.13it/s, loss=2.58] \u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 17/250 [00:15<03:26,  1.13it/s, loss=2.58]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 17/250 [00:15<03:26,  1.13it/s, loss=0.74]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 18/250 [00:16<03:26,  1.13it/s, loss=0.74]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 18/250 [00:16<03:26,  1.13it/s, loss=0.59]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 19/250 [00:17<03:25,  1.13it/s, loss=0.59]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 19/250 [00:17<03:25,  1.13it/s, loss=0.73]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 20/250 [00:18<03:24,  1.12it/s, loss=0.73]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 20/250 [00:18<03:24,  1.12it/s, loss=0.613]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 21/250 [00:19<03:24,  1.12it/s, loss=0.613]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 21/250 [00:19<03:24,  1.12it/s, loss=0.645]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 22/250 [00:20<03:23,  1.12it/s, loss=0.645]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 22/250 [00:20<03:23,  1.12it/s, loss=0.731]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 23/250 [00:20<03:22,  1.12it/s, loss=0.731]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 23/250 [00:20<03:22,  1.12it/s, loss=0.744]\u001b[A\n",
      "Train step of epoch 0:  10%|▉         | 24/250 [00:21<03:22,  1.12it/s, loss=0.744]\u001b[A\n",
      "Train step of epoch 0:  10%|▉         | 24/250 [00:21<03:22,  1.12it/s, loss=0.693]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 25/250 [00:22<03:22,  1.11it/s, loss=0.693]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 25/250 [00:22<03:22,  1.11it/s, loss=0.607]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 26/250 [00:23<03:21,  1.11it/s, loss=0.607]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 26/250 [00:23<03:21,  1.11it/s, loss=0.646]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 27/250 [00:24<03:20,  1.11it/s, loss=0.646]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 27/250 [00:24<03:20,  1.11it/s, loss=0.621]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 28/250 [00:25<03:19,  1.11it/s, loss=0.621]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 28/250 [00:25<03:19,  1.11it/s, loss=0.549]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 29/250 [00:26<03:19,  1.11it/s, loss=0.549]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 29/250 [00:26<03:19,  1.11it/s, loss=0.526]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 30/250 [00:27<03:19,  1.10it/s, loss=0.526]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 30/250 [00:27<03:19,  1.10it/s, loss=0.5]  \u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 31/250 [00:28<03:18,  1.10it/s, loss=0.5]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 31/250 [00:28<03:18,  1.10it/s, loss=0.461]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 32/250 [00:29<03:18,  1.10it/s, loss=0.461]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 32/250 [00:29<03:18,  1.10it/s, loss=0.829]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 33/250 [00:30<03:17,  1.10it/s, loss=0.829]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 33/250 [00:30<03:17,  1.10it/s, loss=0.468]\u001b[A\n",
      "Train step of epoch 0:  14%|█▎        | 34/250 [00:30<03:16,  1.10it/s, loss=0.468]\u001b[A\n",
      "Train step of epoch 0:  14%|█▎        | 34/250 [00:30<03:16,  1.10it/s, loss=0.461]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 35/250 [00:31<03:15,  1.10it/s, loss=0.461]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 35/250 [00:31<03:15,  1.10it/s, loss=0.742]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 36/250 [00:32<03:14,  1.10it/s, loss=0.742]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 36/250 [00:32<03:14,  1.10it/s, loss=1.17] \u001b[A\n",
      "Train step of epoch 0:  15%|█▍        | 37/250 [00:33<03:13,  1.10it/s, loss=1.17]\u001b[A\n",
      "Train step of epoch 0:  15%|█▍        | 37/250 [00:33<03:13,  1.10it/s, loss=0.817]\u001b[A\n",
      "Train step of epoch 0:  15%|█▌        | 38/250 [00:34<03:11,  1.11it/s, loss=0.817]\u001b[A\n",
      "Train step of epoch 0:  15%|█▌        | 38/250 [00:34<03:11,  1.11it/s, loss=0.629]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 39/250 [00:35<03:10,  1.11it/s, loss=0.629]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 39/250 [00:35<03:10,  1.11it/s, loss=0.904]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 40/250 [00:36<03:09,  1.11it/s, loss=0.904]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 40/250 [00:36<03:09,  1.11it/s, loss=0.472]\u001b[A\n",
      "Train step of epoch 0:  16%|█▋        | 41/250 [00:37<03:08,  1.11it/s, loss=0.472]\u001b[A\n",
      "Train step of epoch 0:  16%|█▋        | 41/250 [00:37<03:08,  1.11it/s, loss=0.384]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 42/250 [00:38<03:06,  1.11it/s, loss=0.384]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 42/250 [00:38<03:06,  1.11it/s, loss=0.749]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 43/250 [00:39<03:05,  1.12it/s, loss=0.749]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 43/250 [00:39<03:05,  1.12it/s, loss=0.682]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 44/250 [00:39<03:04,  1.12it/s, loss=0.682]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 44/250 [00:39<03:04,  1.12it/s, loss=1.12] \u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 45/250 [00:40<03:03,  1.12it/s, loss=1.12]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 45/250 [00:40<03:03,  1.12it/s, loss=0.634]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 46/250 [00:41<03:02,  1.12it/s, loss=0.634]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 46/250 [00:41<03:02,  1.12it/s, loss=0.522]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 47/250 [00:42<03:00,  1.12it/s, loss=0.522]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step of epoch 0:  19%|█▉        | 47/250 [00:42<03:00,  1.12it/s, loss=0.687]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 48/250 [00:43<02:59,  1.12it/s, loss=0.687]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 48/250 [00:43<02:59,  1.12it/s, loss=0.814]\u001b[A\n",
      "Train step of epoch 0:  20%|█▉        | 49/250 [00:44<02:58,  1.12it/s, loss=0.814]\u001b[A\n",
      "Train step of epoch 0:  20%|█▉        | 49/250 [00:44<02:58,  1.12it/s, loss=0.652]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 50/250 [00:45<02:57,  1.13it/s, loss=0.652]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 50/250 [00:45<02:57,  1.13it/s, loss=0.818]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 51/250 [00:46<02:56,  1.13it/s, loss=0.818]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 51/250 [00:46<02:56,  1.13it/s, loss=0.434]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 52/250 [00:47<02:55,  1.13it/s, loss=0.434]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 52/250 [00:47<02:55,  1.13it/s, loss=0.629]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 53/250 [00:47<02:54,  1.13it/s, loss=0.629]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 53/250 [00:47<02:54,  1.13it/s, loss=0.504]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 54/250 [00:48<02:53,  1.13it/s, loss=0.504]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 54/250 [00:48<02:53,  1.13it/s, loss=0.382]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 55/250 [00:49<02:52,  1.13it/s, loss=0.382]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 55/250 [00:49<02:52,  1.13it/s, loss=0.593]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 56/250 [00:50<02:51,  1.13it/s, loss=0.593]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 56/250 [00:50<02:51,  1.13it/s, loss=0.637]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 57/250 [00:51<02:50,  1.14it/s, loss=0.637]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 57/250 [00:51<02:50,  1.14it/s, loss=0.604]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 58/250 [00:52<02:48,  1.14it/s, loss=0.604]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 58/250 [00:52<02:48,  1.14it/s, loss=0.464]\u001b[A\n",
      "Train step of epoch 0:  24%|██▎       | 59/250 [00:53<02:48,  1.14it/s, loss=0.464]\u001b[A\n",
      "Train step of epoch 0:  24%|██▎       | 59/250 [00:53<02:48,  1.14it/s, loss=0.526]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 60/250 [00:54<02:47,  1.14it/s, loss=0.526]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 60/250 [00:54<02:47,  1.14it/s, loss=0.39] \u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 61/250 [00:54<02:46,  1.14it/s, loss=0.39]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 61/250 [00:54<02:46,  1.14it/s, loss=0.943]\u001b[A\n",
      "Train step of epoch 0:  25%|██▍       | 62/250 [00:55<02:45,  1.14it/s, loss=0.943]\u001b[A\n",
      "Train step of epoch 0:  25%|██▍       | 62/250 [00:55<02:45,  1.14it/s, loss=0.253]\u001b[A\n",
      "Train step of epoch 0:  25%|██▌       | 63/250 [00:56<02:44,  1.14it/s, loss=0.253]\u001b[A\n",
      "Train step of epoch 0:  25%|██▌       | 63/250 [00:56<02:44,  1.14it/s, loss=0.875]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 64/250 [00:57<02:43,  1.14it/s, loss=0.875]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 64/250 [00:57<02:43,  1.14it/s, loss=0.344]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 65/250 [00:58<02:42,  1.14it/s, loss=0.344]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 65/250 [00:58<02:42,  1.14it/s, loss=0.618]\u001b[A\n",
      "Train step of epoch 0:  26%|██▋       | 66/250 [00:59<02:41,  1.14it/s, loss=0.618]\u001b[A\n",
      "Train step of epoch 0:  26%|██▋       | 66/250 [00:59<02:41,  1.14it/s, loss=0.153]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 67/250 [01:00<02:40,  1.14it/s, loss=0.153]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 67/250 [01:00<02:40,  1.14it/s, loss=0.918]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 68/250 [01:01<02:39,  1.14it/s, loss=0.918]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 68/250 [01:01<02:39,  1.14it/s, loss=0.3]  \u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 69/250 [01:01<02:38,  1.14it/s, loss=0.3]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 69/250 [01:01<02:38,  1.14it/s, loss=0.814]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 70/250 [01:02<02:37,  1.14it/s, loss=0.814]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 70/250 [01:02<02:37,  1.14it/s, loss=0.891]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 71/250 [01:03<02:36,  1.14it/s, loss=0.891]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 71/250 [01:03<02:36,  1.14it/s, loss=0.488]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 72/250 [01:04<02:35,  1.14it/s, loss=0.488]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 72/250 [01:04<02:35,  1.14it/s, loss=1.03] \u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 73/250 [01:05<02:34,  1.14it/s, loss=1.03]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 73/250 [01:05<02:34,  1.14it/s, loss=0.883]\u001b[A\n",
      "Train step of epoch 0:  30%|██▉       | 74/250 [01:06<02:33,  1.15it/s, loss=0.883]\u001b[A\n",
      "Train step of epoch 0:  30%|██▉       | 74/250 [01:06<02:33,  1.15it/s, loss=0.5]  \u001b[A\n",
      "Train step of epoch 0:  30%|███       | 75/250 [01:07<02:32,  1.15it/s, loss=0.5]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 75/250 [01:07<02:32,  1.15it/s, loss=0.595]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 76/250 [01:08<02:31,  1.15it/s, loss=0.595]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 76/250 [01:08<02:31,  1.15it/s, loss=0.732]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 77/250 [01:08<02:31,  1.15it/s, loss=0.732]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 77/250 [01:08<02:31,  1.15it/s, loss=0.457]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 78/250 [01:09<02:30,  1.14it/s, loss=0.457]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 78/250 [01:09<02:30,  1.14it/s, loss=0.573]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 79/250 [01:10<02:29,  1.15it/s, loss=0.573]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 79/250 [01:10<02:29,  1.15it/s, loss=0.609]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 80/250 [01:11<02:28,  1.15it/s, loss=0.609]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 80/250 [01:11<02:28,  1.15it/s, loss=0.705]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 81/250 [01:12<02:27,  1.15it/s, loss=0.705]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 81/250 [01:12<02:27,  1.15it/s, loss=0.406]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 82/250 [01:13<02:26,  1.15it/s, loss=0.406]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 82/250 [01:13<02:26,  1.15it/s, loss=0.787]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 83/250 [01:14<02:25,  1.15it/s, loss=0.787]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 83/250 [01:14<02:25,  1.15it/s, loss=0.631]\u001b[A\n",
      "Train step of epoch 0:  34%|███▎      | 84/250 [01:15<02:24,  1.15it/s, loss=0.631]\u001b[A\n",
      "Train step of epoch 0:  34%|███▎      | 84/250 [01:15<02:24,  1.15it/s, loss=0.647]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 85/250 [01:15<02:23,  1.15it/s, loss=0.647]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 85/250 [01:15<02:23,  1.15it/s, loss=0.682]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 86/250 [01:16<02:23,  1.15it/s, loss=0.682]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 86/250 [01:16<02:23,  1.15it/s, loss=0.593]\u001b[A\n",
      "Train step of epoch 0:  35%|███▍      | 87/250 [01:17<02:22,  1.14it/s, loss=0.593]\u001b[A\n",
      "Train step of epoch 0:  35%|███▍      | 87/250 [01:17<02:22,  1.14it/s, loss=0.552]\u001b[A\n",
      "Train step of epoch 0:  35%|███▌      | 88/250 [01:18<02:21,  1.15it/s, loss=0.552]\u001b[A\n",
      "Train step of epoch 0:  35%|███▌      | 88/250 [01:18<02:21,  1.15it/s, loss=0.855]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 89/250 [01:19<02:20,  1.15it/s, loss=0.855]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 89/250 [01:19<02:20,  1.15it/s, loss=0.749]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 90/250 [01:20<02:19,  1.15it/s, loss=0.749]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 90/250 [01:20<02:19,  1.15it/s, loss=0.711]\u001b[A\n",
      "Train step of epoch 0:  36%|███▋      | 91/250 [01:21<02:18,  1.14it/s, loss=0.711]\u001b[A\n",
      "Train step of epoch 0:  36%|███▋      | 91/250 [01:21<02:18,  1.14it/s, loss=0.68] \u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 92/250 [01:22<02:18,  1.14it/s, loss=0.68]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 92/250 [01:22<02:18,  1.14it/s, loss=0.663]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 93/250 [01:22<02:17,  1.14it/s, loss=0.663]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 93/250 [01:22<02:17,  1.14it/s, loss=0.835]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 94/250 [01:23<02:16,  1.14it/s, loss=0.835]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step of epoch 0:  38%|███▊      | 94/250 [01:23<02:16,  1.14it/s, loss=0.74] \u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 95/250 [01:24<02:15,  1.14it/s, loss=0.74]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 95/250 [01:24<02:15,  1.14it/s, loss=0.536]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 96/250 [01:25<02:14,  1.14it/s, loss=0.536]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 96/250 [01:25<02:14,  1.14it/s, loss=0.694]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 97/250 [01:26<02:14,  1.14it/s, loss=0.694]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 97/250 [01:26<02:14,  1.14it/s, loss=0.822]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 98/250 [01:27<02:13,  1.14it/s, loss=0.822]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 98/250 [01:27<02:13,  1.14it/s, loss=0.714]\u001b[A\n",
      "Train step of epoch 0:  40%|███▉      | 99/250 [01:28<02:12,  1.14it/s, loss=0.714]\u001b[A\n",
      "Train step of epoch 0:  40%|███▉      | 99/250 [01:28<02:12,  1.14it/s, loss=0.576]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 100/250 [01:29<02:11,  1.14it/s, loss=0.576]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 100/250 [01:29<02:11,  1.14it/s, loss=0.678]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 101/250 [01:29<02:10,  1.14it/s, loss=0.678]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 101/250 [01:29<02:10,  1.14it/s, loss=0.681]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 102/250 [01:30<02:09,  1.14it/s, loss=0.681]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 102/250 [01:30<02:09,  1.14it/s, loss=0.664]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 103/250 [01:31<02:08,  1.14it/s, loss=0.664]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 103/250 [01:31<02:08,  1.14it/s, loss=0.683]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 104/250 [01:32<02:08,  1.14it/s, loss=0.683]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 104/250 [01:32<02:08,  1.14it/s, loss=0.758]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 105/250 [01:33<02:07,  1.14it/s, loss=0.758]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 105/250 [01:33<02:07,  1.14it/s, loss=0.683]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 106/250 [01:34<02:06,  1.14it/s, loss=0.683]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 106/250 [01:34<02:06,  1.14it/s, loss=0.604]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 107/250 [01:35<02:05,  1.14it/s, loss=0.604]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 107/250 [01:35<02:05,  1.14it/s, loss=0.769]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 108/250 [01:36<02:04,  1.14it/s, loss=0.769]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 108/250 [01:36<02:04,  1.14it/s, loss=0.546]\u001b[A\n",
      "Train step of epoch 0:  44%|████▎     | 109/250 [01:36<02:04,  1.14it/s, loss=0.546]\u001b[A\n",
      "Train step of epoch 0:  44%|████▎     | 109/250 [01:36<02:04,  1.14it/s, loss=0.642]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 110/250 [01:37<02:03,  1.14it/s, loss=0.642]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 110/250 [01:37<02:03,  1.14it/s, loss=0.763]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 111/250 [01:38<02:02,  1.14it/s, loss=0.763]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 111/250 [01:38<02:02,  1.14it/s, loss=0.594]\u001b[A\n",
      "Train step of epoch 0:  45%|████▍     | 112/250 [01:39<02:01,  1.14it/s, loss=0.594]\u001b[A\n",
      "Train step of epoch 0:  45%|████▍     | 112/250 [01:39<02:01,  1.14it/s, loss=0.61] \u001b[A\n",
      "Train step of epoch 0:  45%|████▌     | 113/250 [01:40<02:00,  1.14it/s, loss=0.61]\u001b[A\n",
      "Train step of epoch 0:  45%|████▌     | 113/250 [01:40<02:00,  1.14it/s, loss=0.692]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 114/250 [01:41<01:59,  1.14it/s, loss=0.692]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 114/250 [01:41<01:59,  1.14it/s, loss=0.878]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 115/250 [01:42<01:58,  1.14it/s, loss=0.878]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 115/250 [01:42<01:58,  1.14it/s, loss=0.702]\u001b[A\n",
      "Train step of epoch 0:  46%|████▋     | 116/250 [01:43<01:58,  1.13it/s, loss=0.702]\u001b[A\n",
      "Train step of epoch 0:  46%|████▋     | 116/250 [01:43<01:58,  1.13it/s, loss=0.572]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 117/250 [01:44<01:57,  1.13it/s, loss=0.572]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 117/250 [01:44<01:57,  1.13it/s, loss=0.522]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 118/250 [01:44<01:56,  1.13it/s, loss=0.522]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 118/250 [01:44<01:56,  1.13it/s, loss=0.537]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 119/250 [01:45<01:55,  1.13it/s, loss=0.537]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 119/250 [01:45<01:55,  1.13it/s, loss=0.514]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 120/250 [01:46<01:54,  1.13it/s, loss=0.514]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 120/250 [01:46<01:54,  1.13it/s, loss=0.982]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 121/250 [01:47<01:53,  1.13it/s, loss=0.982]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 121/250 [01:47<01:53,  1.13it/s, loss=0.774]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 122/250 [01:48<01:53,  1.13it/s, loss=0.774]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 122/250 [01:48<01:53,  1.13it/s, loss=0.643]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 123/250 [01:49<01:52,  1.13it/s, loss=0.643]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 123/250 [01:49<01:52,  1.13it/s, loss=0.547]\u001b[A\n",
      "Train step of epoch 0:  50%|████▉     | 124/250 [01:50<01:51,  1.13it/s, loss=0.547]\u001b[A\n",
      "Train step of epoch 0:  50%|████▉     | 124/250 [01:50<01:51,  1.13it/s, loss=0.702]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 125/250 [01:51<01:50,  1.13it/s, loss=0.702]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 125/250 [01:51<01:50,  1.13it/s, loss=0.746]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 126/250 [01:51<01:49,  1.13it/s, loss=0.746]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 126/250 [01:51<01:49,  1.13it/s, loss=0.675]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 127/250 [01:52<01:48,  1.13it/s, loss=0.675]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 127/250 [01:52<01:48,  1.13it/s, loss=0.579]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 128/250 [01:53<01:47,  1.13it/s, loss=0.579]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 128/250 [01:53<01:47,  1.13it/s, loss=0.561]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 129/250 [01:54<01:46,  1.13it/s, loss=0.561]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 129/250 [01:54<01:46,  1.13it/s, loss=0.634]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 130/250 [01:55<01:45,  1.13it/s, loss=0.634]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 130/250 [01:55<01:45,  1.13it/s, loss=0.545]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 131/250 [01:56<01:45,  1.13it/s, loss=0.545]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 131/250 [01:56<01:45,  1.13it/s, loss=1]    \u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 132/250 [01:57<01:44,  1.13it/s, loss=1]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 132/250 [01:57<01:44,  1.13it/s, loss=0.616]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 133/250 [01:58<01:43,  1.13it/s, loss=0.616]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 133/250 [01:58<01:43,  1.13it/s, loss=0.917]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▎    | 134/250 [01:59<01:42,  1.13it/s, loss=0.917]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▎    | 134/250 [01:59<01:42,  1.13it/s, loss=0.739]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 135/250 [01:59<01:41,  1.13it/s, loss=0.739]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 135/250 [01:59<01:41,  1.13it/s, loss=0.711]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 136/250 [02:00<01:40,  1.13it/s, loss=0.711]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 136/250 [02:00<01:40,  1.13it/s, loss=0.679]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▍    | 137/250 [02:01<01:39,  1.13it/s, loss=0.679]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▍    | 137/250 [02:01<01:39,  1.13it/s, loss=0.573]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▌    | 138/250 [02:02<01:38,  1.13it/s, loss=0.573]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▌    | 138/250 [02:02<01:38,  1.13it/s, loss=0.629]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 139/250 [02:03<01:37,  1.14it/s, loss=0.629]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 139/250 [02:03<01:37,  1.14it/s, loss=0.555]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 140/250 [02:04<01:36,  1.14it/s, loss=0.555]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 140/250 [02:04<01:36,  1.14it/s, loss=0.554]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step of epoch 0:  56%|█████▋    | 141/250 [02:05<01:36,  1.13it/s, loss=0.554]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▋    | 141/250 [02:05<01:36,  1.13it/s, loss=0.59] \u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 142/250 [02:06<01:35,  1.13it/s, loss=0.59]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 142/250 [02:06<01:35,  1.13it/s, loss=0.798]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 143/250 [02:06<01:34,  1.14it/s, loss=0.798]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 143/250 [02:06<01:34,  1.14it/s, loss=0.605]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 144/250 [02:07<01:33,  1.14it/s, loss=0.605]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 144/250 [02:07<01:33,  1.14it/s, loss=0.552]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 145/250 [02:08<01:32,  1.13it/s, loss=0.552]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 145/250 [02:08<01:32,  1.13it/s, loss=0.652]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 146/250 [02:09<01:31,  1.13it/s, loss=0.652]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 146/250 [02:09<01:31,  1.13it/s, loss=0.63] \u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 147/250 [02:10<01:30,  1.13it/s, loss=0.63]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 147/250 [02:10<01:30,  1.13it/s, loss=0.391]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 148/250 [02:11<01:29,  1.13it/s, loss=0.391]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 148/250 [02:11<01:29,  1.13it/s, loss=0.635]\u001b[A\n",
      "Train step of epoch 0:  60%|█████▉    | 149/250 [02:12<01:29,  1.13it/s, loss=0.635]\u001b[A\n",
      "Train step of epoch 0:  60%|█████▉    | 149/250 [02:12<01:29,  1.13it/s, loss=0.582]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 150/250 [02:13<01:28,  1.13it/s, loss=0.582]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 150/250 [02:13<01:28,  1.13it/s, loss=0.588]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 151/250 [02:14<01:27,  1.13it/s, loss=0.588]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 151/250 [02:14<01:27,  1.13it/s, loss=0.291]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 152/250 [02:14<01:26,  1.13it/s, loss=0.291]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 152/250 [02:14<01:26,  1.13it/s, loss=0.51] \u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 153/250 [02:15<01:25,  1.13it/s, loss=0.51]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 153/250 [02:15<01:25,  1.13it/s, loss=0.669]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 154/250 [02:16<01:24,  1.13it/s, loss=0.669]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 154/250 [02:16<01:24,  1.13it/s, loss=0.916]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 155/250 [02:17<01:23,  1.13it/s, loss=0.916]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 155/250 [02:17<01:23,  1.13it/s, loss=1.11] \u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 156/250 [02:18<01:22,  1.13it/s, loss=1.11]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 156/250 [02:18<01:22,  1.13it/s, loss=0.475]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 157/250 [02:19<01:21,  1.13it/s, loss=0.475]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 157/250 [02:19<01:21,  1.13it/s, loss=0.384]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 158/250 [02:20<01:21,  1.14it/s, loss=0.384]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 158/250 [02:20<01:21,  1.14it/s, loss=0.713]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▎   | 159/250 [02:21<01:20,  1.13it/s, loss=0.713]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▎   | 159/250 [02:21<01:20,  1.13it/s, loss=0.66] \u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 160/250 [02:21<01:19,  1.14it/s, loss=0.66]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 160/250 [02:21<01:19,  1.14it/s, loss=0.428]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 161/250 [02:22<01:18,  1.13it/s, loss=0.428]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 161/250 [02:22<01:18,  1.13it/s, loss=0.642]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▍   | 162/250 [02:23<01:17,  1.14it/s, loss=0.642]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▍   | 162/250 [02:23<01:17,  1.14it/s, loss=0.38] \u001b[A\n",
      "Train step of epoch 0:  65%|██████▌   | 163/250 [02:24<01:16,  1.14it/s, loss=0.38]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▌   | 163/250 [02:24<01:16,  1.14it/s, loss=0.326]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 164/250 [02:25<01:15,  1.14it/s, loss=0.326]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 164/250 [02:25<01:15,  1.14it/s, loss=0.628]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 165/250 [02:26<01:14,  1.14it/s, loss=0.628]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 165/250 [02:26<01:14,  1.14it/s, loss=1.01] \u001b[A\n",
      "Train step of epoch 0:  66%|██████▋   | 166/250 [02:27<01:13,  1.14it/s, loss=1.01]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▋   | 166/250 [02:27<01:13,  1.14it/s, loss=0.329]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 167/250 [02:28<01:12,  1.14it/s, loss=0.329]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 167/250 [02:28<01:12,  1.14it/s, loss=0.278]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 168/250 [02:28<01:12,  1.14it/s, loss=0.278]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 168/250 [02:28<01:12,  1.14it/s, loss=0.505]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 169/250 [02:29<01:11,  1.13it/s, loss=0.505]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 169/250 [02:29<01:11,  1.13it/s, loss=0.362]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 170/250 [02:30<01:10,  1.13it/s, loss=0.362]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 170/250 [02:30<01:10,  1.13it/s, loss=1.14] \u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 171/250 [02:31<01:09,  1.14it/s, loss=1.14]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 171/250 [02:31<01:09,  1.14it/s, loss=0.875]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 172/250 [02:32<01:08,  1.14it/s, loss=0.875]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 172/250 [02:32<01:08,  1.14it/s, loss=0.826]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 173/250 [02:33<01:07,  1.14it/s, loss=0.826]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 173/250 [02:33<01:07,  1.14it/s, loss=0.526]\u001b[A\n",
      "Train step of epoch 0:  70%|██████▉   | 174/250 [02:34<01:06,  1.14it/s, loss=0.526]\u001b[A\n",
      "Train step of epoch 0:  70%|██████▉   | 174/250 [02:34<01:06,  1.14it/s, loss=0.471]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 175/250 [02:35<01:05,  1.14it/s, loss=0.471]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 175/250 [02:35<01:05,  1.14it/s, loss=0.623]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 176/250 [02:36<01:05,  1.14it/s, loss=0.623]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 176/250 [02:36<01:05,  1.14it/s, loss=0.53] \u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 177/250 [02:36<01:04,  1.14it/s, loss=0.53]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 177/250 [02:36<01:04,  1.14it/s, loss=0.404]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 178/250 [02:37<01:03,  1.14it/s, loss=0.404]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 178/250 [02:37<01:03,  1.14it/s, loss=0.425]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 179/250 [02:38<01:02,  1.14it/s, loss=0.425]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 179/250 [02:38<01:02,  1.14it/s, loss=0.55] \u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 180/250 [02:39<01:01,  1.13it/s, loss=0.55]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 180/250 [02:39<01:01,  1.13it/s, loss=0.972]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 181/250 [02:40<01:00,  1.13it/s, loss=0.972]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 181/250 [02:40<01:00,  1.13it/s, loss=0.322]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 182/250 [02:41<00:59,  1.13it/s, loss=0.322]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 182/250 [02:41<00:59,  1.13it/s, loss=0.931]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 183/250 [02:42<00:59,  1.13it/s, loss=0.931]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 183/250 [02:42<00:59,  1.13it/s, loss=1.3]  \u001b[A\n",
      "Train step of epoch 0:  74%|███████▎  | 184/250 [02:43<00:58,  1.13it/s, loss=1.3]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▎  | 184/250 [02:43<00:58,  1.13it/s, loss=0.785]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 185/250 [02:43<00:57,  1.14it/s, loss=0.785]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 185/250 [02:43<00:57,  1.14it/s, loss=0.625]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 186/250 [02:44<00:56,  1.14it/s, loss=0.625]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 186/250 [02:44<00:56,  1.14it/s, loss=0.534]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▍  | 187/250 [02:45<00:55,  1.14it/s, loss=0.534]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step of epoch 0:  75%|███████▍  | 187/250 [02:45<00:55,  1.14it/s, loss=0.504]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▌  | 188/250 [02:46<00:54,  1.14it/s, loss=0.504]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▌  | 188/250 [02:46<00:54,  1.14it/s, loss=0.624]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 189/250 [02:47<00:53,  1.14it/s, loss=0.624]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 189/250 [02:47<00:53,  1.14it/s, loss=0.661]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 190/250 [02:48<00:52,  1.14it/s, loss=0.661]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 190/250 [02:48<00:52,  1.14it/s, loss=0.578]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▋  | 191/250 [02:49<00:51,  1.14it/s, loss=0.578]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▋  | 191/250 [02:49<00:51,  1.14it/s, loss=0.571]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 192/250 [02:50<00:50,  1.14it/s, loss=0.571]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 192/250 [02:50<00:50,  1.14it/s, loss=0.489]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 193/250 [02:50<00:50,  1.14it/s, loss=0.489]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 193/250 [02:51<00:50,  1.14it/s, loss=0.729]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 194/250 [02:51<00:49,  1.14it/s, loss=0.729]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 194/250 [02:51<00:49,  1.14it/s, loss=0.661]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 195/250 [02:52<00:48,  1.14it/s, loss=0.661]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 195/250 [02:52<00:48,  1.14it/s, loss=0.498]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 196/250 [02:53<00:47,  1.14it/s, loss=0.498]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 196/250 [02:53<00:47,  1.14it/s, loss=0.869]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 197/250 [02:54<00:46,  1.14it/s, loss=0.869]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 197/250 [02:54<00:46,  1.14it/s, loss=0.617]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 198/250 [02:55<00:45,  1.14it/s, loss=0.617]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 198/250 [02:55<00:45,  1.14it/s, loss=0.587]\u001b[A\n",
      "Train step of epoch 0:  80%|███████▉  | 199/250 [02:56<00:44,  1.14it/s, loss=0.587]\u001b[A\n",
      "Train step of epoch 0:  80%|███████▉  | 199/250 [02:56<00:44,  1.14it/s, loss=0.403]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 200/250 [02:57<00:43,  1.14it/s, loss=0.403]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 200/250 [02:57<00:43,  1.14it/s, loss=0.523]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 201/250 [02:58<00:43,  1.14it/s, loss=0.523]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 201/250 [02:58<00:43,  1.14it/s, loss=0.455]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 202/250 [02:58<00:42,  1.14it/s, loss=0.455]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 202/250 [02:58<00:42,  1.14it/s, loss=0.794]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 203/250 [02:59<00:41,  1.14it/s, loss=0.794]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 203/250 [02:59<00:41,  1.14it/s, loss=0.573]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 204/250 [03:00<00:40,  1.14it/s, loss=0.573]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 204/250 [03:00<00:40,  1.14it/s, loss=0.471]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 205/250 [03:01<00:39,  1.14it/s, loss=0.471]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 205/250 [03:01<00:39,  1.14it/s, loss=0.491]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 206/250 [03:02<00:38,  1.14it/s, loss=0.491]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 206/250 [03:02<00:38,  1.14it/s, loss=0.913]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 207/250 [03:03<00:37,  1.14it/s, loss=0.913]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 207/250 [03:03<00:37,  1.14it/s, loss=0.47] \u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 208/250 [03:04<00:36,  1.14it/s, loss=0.47]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 208/250 [03:04<00:36,  1.14it/s, loss=0.642]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▎ | 209/250 [03:05<00:36,  1.14it/s, loss=0.642]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▎ | 209/250 [03:05<00:36,  1.14it/s, loss=0.57] \u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 210/250 [03:05<00:35,  1.14it/s, loss=0.57]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 210/250 [03:05<00:35,  1.14it/s, loss=0.976]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 211/250 [03:06<00:34,  1.14it/s, loss=0.976]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 211/250 [03:06<00:34,  1.14it/s, loss=0.451]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▍ | 212/250 [03:07<00:33,  1.14it/s, loss=0.451]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▍ | 212/250 [03:07<00:33,  1.14it/s, loss=0.431]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▌ | 213/250 [03:08<00:32,  1.14it/s, loss=0.431]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▌ | 213/250 [03:08<00:32,  1.14it/s, loss=0.607]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 214/250 [03:09<00:31,  1.14it/s, loss=0.607]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 214/250 [03:09<00:31,  1.14it/s, loss=1.11] \u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 215/250 [03:10<00:30,  1.14it/s, loss=1.11]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 215/250 [03:10<00:30,  1.14it/s, loss=0.601]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▋ | 216/250 [03:11<00:29,  1.14it/s, loss=0.601]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▋ | 216/250 [03:11<00:29,  1.14it/s, loss=0.717]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 217/250 [03:12<00:28,  1.14it/s, loss=0.717]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 217/250 [03:12<00:28,  1.14it/s, loss=0.711]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 218/250 [03:12<00:28,  1.14it/s, loss=0.711]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 218/250 [03:12<00:28,  1.14it/s, loss=0.507]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 219/250 [03:13<00:27,  1.14it/s, loss=0.507]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 219/250 [03:13<00:27,  1.14it/s, loss=0.536]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 220/250 [03:14<00:26,  1.14it/s, loss=0.536]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 220/250 [03:14<00:26,  1.14it/s, loss=0.657]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 221/250 [03:15<00:25,  1.14it/s, loss=0.657]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 221/250 [03:15<00:25,  1.14it/s, loss=0.774]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 222/250 [03:16<00:24,  1.14it/s, loss=0.774]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 222/250 [03:16<00:24,  1.14it/s, loss=0.347]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 223/250 [03:17<00:23,  1.14it/s, loss=0.347]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 223/250 [03:17<00:23,  1.14it/s, loss=0.791]\u001b[A\n",
      "Train step of epoch 0:  90%|████████▉ | 224/250 [03:18<00:22,  1.14it/s, loss=0.791]\u001b[A\n",
      "Train step of epoch 0:  90%|████████▉ | 224/250 [03:18<00:22,  1.14it/s, loss=0.744]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 225/250 [03:19<00:21,  1.14it/s, loss=0.744]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 225/250 [03:19<00:21,  1.14it/s, loss=0.726]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 226/250 [03:19<00:21,  1.14it/s, loss=0.726]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 226/250 [03:20<00:21,  1.14it/s, loss=0.699]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 227/250 [03:20<00:20,  1.14it/s, loss=0.699]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 227/250 [03:20<00:20,  1.14it/s, loss=0.705]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 228/250 [03:21<00:19,  1.14it/s, loss=0.705]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 228/250 [03:21<00:19,  1.14it/s, loss=0.553]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 229/250 [03:22<00:18,  1.14it/s, loss=0.553]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 229/250 [03:22<00:18,  1.14it/s, loss=0.799]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 230/250 [03:23<00:17,  1.14it/s, loss=0.799]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 230/250 [03:23<00:17,  1.14it/s, loss=0.686]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 231/250 [03:24<00:16,  1.14it/s, loss=0.686]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 231/250 [03:24<00:16,  1.14it/s, loss=0.426]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 232/250 [03:25<00:15,  1.14it/s, loss=0.426]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 232/250 [03:25<00:15,  1.14it/s, loss=0.796]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 233/250 [03:26<00:14,  1.14it/s, loss=0.796]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 233/250 [03:26<00:14,  1.14it/s, loss=0.474]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step of epoch 0:  94%|█████████▎| 234/250 [03:27<00:14,  1.14it/s, loss=0.474]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▎| 234/250 [03:27<00:14,  1.14it/s, loss=0.522]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 235/250 [03:27<00:13,  1.14it/s, loss=0.522]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 235/250 [03:27<00:13,  1.14it/s, loss=0.838]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 236/250 [03:28<00:12,  1.14it/s, loss=0.838]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 236/250 [03:28<00:12,  1.14it/s, loss=0.507]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▍| 237/250 [03:29<00:11,  1.14it/s, loss=0.507]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▍| 237/250 [03:29<00:11,  1.14it/s, loss=0.523]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▌| 238/250 [03:30<00:10,  1.14it/s, loss=0.523]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▌| 238/250 [03:30<00:10,  1.14it/s, loss=0.708]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 239/250 [03:31<00:09,  1.14it/s, loss=0.708]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 239/250 [03:31<00:09,  1.14it/s, loss=0.655]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 240/250 [03:32<00:08,  1.14it/s, loss=0.655]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 240/250 [03:32<00:08,  1.14it/s, loss=0.662]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▋| 241/250 [03:33<00:07,  1.14it/s, loss=0.662]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▋| 241/250 [03:33<00:07,  1.14it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 242/250 [03:34<00:07,  1.14it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 242/250 [03:34<00:07,  1.14it/s, loss=0.785]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 243/250 [03:34<00:06,  1.14it/s, loss=0.785]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 243/250 [03:34<00:06,  1.14it/s, loss=0.632]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 244/250 [03:35<00:05,  1.14it/s, loss=0.632]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 244/250 [03:35<00:05,  1.14it/s, loss=0.74] \u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 245/250 [03:36<00:04,  1.14it/s, loss=0.74]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 245/250 [03:36<00:04,  1.14it/s, loss=0.844]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 246/250 [03:37<00:03,  1.14it/s, loss=0.844]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 246/250 [03:37<00:03,  1.14it/s, loss=0.774]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 247/250 [03:38<00:02,  1.14it/s, loss=0.774]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 247/250 [03:38<00:02,  1.14it/s, loss=0.423]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 248/250 [03:39<00:01,  1.14it/s, loss=0.423]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 248/250 [03:39<00:01,  1.14it/s, loss=1.04] \u001b[A\n",
      "Train step of epoch 0: 100%|█████████▉| 249/250 [03:40<00:00,  1.14it/s, loss=1.04]\u001b[A\n",
      "Train step of epoch 0: 100%|█████████▉| 249/250 [03:40<00:00,  1.14it/s, loss=0.619]\u001b[A\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [03:41<00:00,  1.14it/s, loss=0.619]\u001b[A\n",
      "Train epoch: 100%|██████████| 1/1 [03:55<00:00, 235.44s/it]0,  1.14it/s, loss=0.51] \u001b[A\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [03:55<00:00,  1.06it/s, loss=0.63, dist_mean=0.21]\u001b[A\n",
      "Train epoch: 100%|██████████| 1/1 [03:55<00:00, 235.44s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer = RewardModelTrainer(model=model,\n",
    "                             strategy=NaiveStrategy(),\n",
    "                             optim=Adam(model.parameters(), lr=5e-5),\n",
    "                             train_dataset=train_dataset,\n",
    "                             eval_dataset=eval_dataset,\n",
    "                             batch_size=4,\n",
    "                             max_epochs=1)\n",
    "\n",
    "trainer.fit(use_lora=0)\n",
    "\n",
    "model.save_pretrained(f\"./model/{save_dir}/output_2_RM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2966e",
   "metadata": {},
   "source": [
    "### 적절한 reward score를 출력하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0bcc7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 똥멍청이 입니다\n",
      "reward score: 2.0\n",
      "input: 인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\n",
      "reward score: 2.7\n"
     ]
    }
   ],
   "source": [
    "def inference_RM(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    output = model(input_ids)\n",
    "    output_reward = output.cpu().detach().numpy()[0]\n",
    "\n",
    "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
    "\n",
    "    return output_reward\n",
    "\n",
    "input_text = '인공지능은 똥멍청이 입니다'\n",
    "output_reward = inference_RM(input_text=input_text)\n",
    "\n",
    "input_text = \"인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\"\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d73375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52963a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "870df784",
   "metadata": {},
   "source": [
    "#### 메모리 관리를 위해 캐시를 비우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e46026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e34b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
