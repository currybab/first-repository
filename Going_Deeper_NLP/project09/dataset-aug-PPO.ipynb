{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7300e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "save_dir = model_name.replace(\"/\", \"__\") + '__data-add'\n",
    "critic_save_dir = \"skt__kogpt2-base-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a2d8b7",
   "metadata": {},
   "source": [
    "### PPO 데이터셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7324e16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?'},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?'},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "data_path_3_PPO = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl'\n",
    "with open(data_path_3_PPO, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict)) # 12000\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f952e740",
   "metadata": {},
   "source": [
    "### 필요한 라이브러리 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e44dfed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659f7e04",
   "metadata": {},
   "source": [
    "### 모델학습에 사용할 옵티마이저와 모델을 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03493af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained=f\"model/{save_dir}/output_1_SFT\", lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained=f\"model/{critic_save_dir}/output_2_RM\", lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name, bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9632de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)\n",
    "\n",
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f75dd99",
   "metadata": {},
   "source": [
    "### PPO 학습에 쓸 데이터를 불러와 토크나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "300aaa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[47311, 10448, 19008,  9792, 11780, 11308, 30190, 10929, 11849, 21663,\n",
      "         44389,  9574, 13799,   458, 14308, 12778, 22469, 20938, 44696,   458,\n",
      "         13799,   458, 14308, 12778, 11756, 18944,   389]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}\n",
    "\n",
    "print(tokenize_fn('It takes something more than intelligence to act intelligently.'))\n",
    "\n",
    "len(list_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ade5584",
   "metadata": {},
   "source": [
    "### PPO Trainer 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff927e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=1,  \n",
    "                     train_batch_size=8, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1201a9e3",
   "metadata": {},
   "source": [
    "### PPO 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8309b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode [1/10]:  67%|██████▋   | 2/3 [00:13<00:06,  6.47s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.00105]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.39it/s, actor_loss=0, critic_loss=0.00105]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.39it/s, actor_loss=0, critic_loss=0.0933] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.65it/s, actor_loss=0, critic_loss=0.0933]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.65it/s, actor_loss=0, critic_loss=0.00431]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.70it/s, actor_loss=0, critic_loss=0.00431]\u001b[A\n",
      "Episode [1/10]: 100%|██████████| 3/3 [00:20<00:00,  6.92s/it]\n",
      "Episode [2/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.94s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.162, critic_loss=0.0267]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=0.162, critic_loss=0.0267]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=0.159, critic_loss=0.0526]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.159, critic_loss=0.0526]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.148, critic_loss=0.0298]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=0.148, critic_loss=0.0298]\u001b[A\n",
      "Episode [2/10]: 100%|██████████| 3/3 [00:19<00:00,  6.49s/it]\n",
      "Episode [3/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.77s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0849, critic_loss=0.00635]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.91it/s, actor_loss=0.0849, critic_loss=0.00635]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.91it/s, actor_loss=0.0681, critic_loss=0.00268]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.91it/s, actor_loss=0.0681, critic_loss=0.00268]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.91it/s, actor_loss=0.0858, critic_loss=0.0188] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.90it/s, actor_loss=0.0858, critic_loss=0.0188]\u001b[A\n",
      "Episode [3/10]: 100%|██████████| 3/3 [00:18<00:00,  6.29s/it]\n",
      "Episode [4/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.70s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.127, critic_loss=0.0237]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.89it/s, actor_loss=-.127, critic_loss=0.0237]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.89it/s, actor_loss=-.127, critic_loss=0.0185]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=-.127, critic_loss=0.0185]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=-.128, critic_loss=0.00376]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.90it/s, actor_loss=-.128, critic_loss=0.00376]\u001b[A\n",
      "Episode [4/10]: 100%|██████████| 3/3 [00:18<00:00,  6.24s/it]\n",
      "Episode [5/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.81s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0117, critic_loss=0.000545]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=-.0117, critic_loss=0.000545]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=0.00128, critic_loss=0.00714]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=0.00128, critic_loss=0.00714]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=0.000209, critic_loss=0.0112]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=0.000209, critic_loss=0.0112]\u001b[A\n",
      "Episode [5/10]: 100%|██████████| 3/3 [00:19<00:00,  6.34s/it]\n",
      "Episode [6/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.78s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.092, critic_loss=0.00858]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=0.092, critic_loss=0.00858]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=0.0987, critic_loss=0.00594]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=0.0987, critic_loss=0.00594]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=0.128, critic_loss=0.00326] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=0.128, critic_loss=0.00326]\u001b[A\n",
      "Episode [6/10]: 100%|██████████| 3/3 [00:18<00:00,  6.32s/it]\n",
      "Episode [7/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.78s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0256, critic_loss=0.000241]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.89it/s, actor_loss=-.0256, critic_loss=0.000241]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.89it/s, actor_loss=-.0147, critic_loss=0.00321] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=-.0147, critic_loss=0.00321]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=-.0191, critic_loss=0.0084] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.89it/s, actor_loss=-.0191, critic_loss=0.0084]\u001b[A\n",
      "Episode [7/10]: 100%|██████████| 3/3 [00:19<00:00,  6.37s/it]\n",
      "Episode [8/10]:  67%|██████▋   | 2/3 [00:10<00:05,  5.39s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0669, critic_loss=0.00717]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.89it/s, actor_loss=-.0669, critic_loss=0.00717]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.89it/s, actor_loss=0.315, critic_loss=0.631]   \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=0.315, critic_loss=0.631]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=-.0117, critic_loss=0.022]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.89it/s, actor_loss=-.0117, critic_loss=0.022]\u001b[A\n",
      "Episode [8/10]: 100%|██████████| 3/3 [00:18<00:00,  6.03s/it]\n",
      "Episode [9/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.83s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0785, critic_loss=0.0228]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.89it/s, actor_loss=-.0785, critic_loss=0.0228]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.89it/s, actor_loss=-.122, critic_loss=0.0222] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=-.122, critic_loss=0.0222]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=-.129, critic_loss=0.0143]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=-.129, critic_loss=0.0143]\u001b[A\n",
      "Episode [9/10]: 100%|██████████| 3/3 [00:19<00:00,  6.36s/it]\n",
      "Episode [10/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.84s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0223, critic_loss=0.00498]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=-.0223, critic_loss=0.00498]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=-.0382, critic_loss=0.00668]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=-.0382, critic_loss=0.00668]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=-.0491, critic_loss=0.00241]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=-.0491, critic_loss=0.00241]\u001b[A\n",
      "Episode [10/10]: 100%|██████████| 3/3 [00:18<00:00,  6.33s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "actor.model.save_pretrained(f'./model/{save_dir}/output_3_PPO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77297d5",
   "metadata": {},
   "source": [
    "### RLHF가 적용된 custom chatgpt의 생성능력을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e24b5be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):저는 인공지능 AI이기 때문에 불고기용 고기의 종류, 판매처 및 위치, 부위에 따라 다를 수 있다고 생각합니다. 일반적으로는 일반적으로 한우는 일반적으로 한우를 사용하며, 다른 종류에서도 사용될 수 있습니다. 따라서 상황에 따라 적합한 메뉴 선택이 필요합니다. 에서는 일반적으로 불고기 양념으로 판매되며, 한우는 한우와 비슷한 고기와 함께 조리될 경우 됩니다. 불고기 한우의 주 재료는 돼지고기로 추정되며, 이는 보통 양고기 국물을 통해 제공됩니다. 에서는 양고기의 경우, 한우를 사용하며, 이는 일반적으로 한우를 사용한다고 됩니다.肉聖敎증명서를先注さらさら? 라고도 합니다.由束其秦皇堂恵眞敎さら\\と士ん srubscurae: フーキミツフと関 さら.ジッキミンダジス 라고도 합니다.秦国境僧流上油できら小さら 에는 일반적으로 쇠고기에서 유래되는 것으로 보입니다.小宮\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):1950년으로 기록됩니다1950년. 으로 부통령직을 수행한. 대통령입니다. 에에 해당하는 정보로서. }  대통령. 대통령, }私後懷明 } 대통령 }, \\ 들의 \\'를 수행했습니다. } er'\\'라는 를 ~. 으로 \\'수행한 따라지지갑니다. } 으로잉클링할 } 私. \\'\" }\\'하고 \\' 으로\\'를 \\'\",\", 'token': 251} } } \\'token': \"어느 \\'을 수행했습니다. \"\", 'token'    \\'\", \\\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어\n",
      "\n",
      "### Response(응답):시카고 오헤어 국제공항은 미국 일리노이 주 시카고에서 찾을 수 있습니다. Americano Birth of Taxiacru이션)은 시카고에서 출발하여 미국 일리노이 주 시카고 지역에 도달할 있습니다. 시카고 오헤어 국제공항은 미국 일리노이 주 시카고 시내에서 가까이, 항공편 및 관광지는 시카고입니다.:: 시카고는 미국 일리노이 주 시카고에서 출발하여 미국 동부 지역에 도착합니다. Americano Birth of Taxiacuer는 시카고에서 출발하여 미국 동부 지역에 도착합니다. Positivate:辰寶:眞 at the translation은 (이러한), (예외)晋辰 フインフミン으로神,高)富士? Americas in English (Os)로 인정되고 있습니다.フックス:眞理寶) \"Where heam\"理士と使んざんる神さら官賓富士 f\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):미세먼지.는평일 미세먼지.를 마시지 않기 때문에 를를않습니다좋습니다좋습니다 마스크와 마스크 착용 및 실내 공기 질 관리를 권장합니다호흡기 잘 마. 미세먼지 않도록노력. 건강에 항상 주의하시기 바랍니다.素らあらら 에. 의 를 사용.에의.을 나타냅니다.\\을미세먼지 가 않도록 합니다.恢宮でる의\\질문에 \"미세먼지\"가 있는지 아닌지 확인하고 대처해야 합니다. 에를 경보하고 대처하는 것이 좋습니다. 』田ら書籍\\ 대처 에 를.경고합니다.田よさん한에게 」미세먼지 측정기 있습니다. \", 대응 을 대응하지 않은 것으로.\\을 대응하지,을미세먼지 말라고경보드립니다.\n"
     ]
    }
   ],
   "source": [
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print()\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "\n",
    "for input_text in list_prompt:\n",
    "    output = generation(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb6d875",
   "metadata": {},
   "source": [
    "#### 메모리 관리를 위해 캐시를 비우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3711223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348c032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
