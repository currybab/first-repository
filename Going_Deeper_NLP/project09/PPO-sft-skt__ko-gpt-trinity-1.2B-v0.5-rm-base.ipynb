{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6fa960",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"skt/ko-gpt-trinity-1.2B-v0.5\"\n",
    "save_dir = model_name.replace(\"/\", \"__\")\n",
    "rm_model_name = \"skt/kogpt2-base-v2\"\n",
    "rm_save_dir = rm_model_name.replace(\"/\", \"__\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb6938",
   "metadata": {},
   "source": [
    "### PPO 데이터셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3032625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?'},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?'},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "data_path_3_PPO = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl'\n",
    "with open(data_path_3_PPO, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict)) # 12000\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abf59e4",
   "metadata": {},
   "source": [
    "### 필요한 라이브러리 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d94019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer, Adafactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62bbaa48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b178ec27",
   "metadata": {},
   "source": [
    "### 모델학습에 사용할 옵티마이저와 모델을 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eabf4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained=f\"model/{save_dir}/output_1_SFT-e3\", lora_rank=0).half().to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained=f\"model/{rm_save_dir}/output_2_RM\", lora_rank=0).half().to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name, bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=128\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4f015c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n",
      "Model is using FP16 for some parameters.\n",
      "torch.float16\n",
      "Model is using FP16 for some parameters.\n"
     ]
    }
   ],
   "source": [
    "for param in actor.parameters():\n",
    "    print(param.dtype)\n",
    "    # Check if the parameter is of type torch.float16\n",
    "    if param.dtype == torch.float16:\n",
    "        print(\"Model is using FP16 for some parameters.\")\n",
    "    else:\n",
    "        print(\"Model is not fully in FP16.\")\n",
    "    break\n",
    "\n",
    "for param in critic.parameters():\n",
    "    print(param.dtype)\n",
    "    # Check if the parameter is of type torch.float16\n",
    "    if param.dtype == torch.float16:\n",
    "        print(\"Model is using FP16 for some parameters.\")\n",
    "    else:\n",
    "        print(\"Model is not fully in FP16.\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c1c4119",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_optim = Adafactor(actor.parameters(), lr=5e-6, relative_step=False)\n",
    "critic_optim = Adafactor(critic.parameters(), lr=5e-6, relative_step=False)\n",
    "\n",
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e731587a",
   "metadata": {},
   "source": [
    "### PPO 학습에 쓸 데이터를 불러와 토크나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e80ce3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[46390, 31369, 33712, 30541, 31338, 41607, 30586, 31024, 31482, 37404,\n",
      "         31035, 30316, 32131,   460, 34763, 32017, 37762, 33441,   565, 37205,\n",
      "         32131,   460, 34763, 32017, 31561, 36271,   390]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}\n",
    "\n",
    "print(tokenize_fn('It takes something more than intelligence to act intelligently.'))\n",
    "\n",
    "len(list_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30bfd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5774a9de",
   "metadata": {},
   "source": [
    "### PPO Trainer 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39ad4f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=1,  \n",
    "                     train_batch_size=8, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d304f12b",
   "metadata": {},
   "source": [
    "### PPO 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ec2282f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode [1/10]:  67%|██████▋   | 2/3 [00:22<00:11, 11.18s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:01<?, ?it/s, actor_loss=0, critic_loss=0.000877]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:02,  1.17s/it, actor_loss=0, critic_loss=0.000877]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:02<00:02,  1.17s/it, actor_loss=0, critic_loss=0.000263]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:02<00:01,  1.18s/it, actor_loss=0, critic_loss=0.000263]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:03<00:01,  1.18s/it, actor_loss=0, critic_loss=0.000573]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:03<00:00,  1.18s/it, actor_loss=0, critic_loss=0.000573]\u001b[A\n",
      "Episode [1/10]: 100%|██████████| 3/3 [00:37<00:00, 12.59s/it]\n",
      "Episode [2/10]:  67%|██████▋   | 2/3 [00:23<00:11, 11.62s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:01<?, ?it/s, actor_loss=-.000121, critic_loss=0.00026]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:02,  1.16s/it, actor_loss=-.000121, critic_loss=0.00026]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:02<00:02,  1.16s/it, actor_loss=-.000116, critic_loss=0.000235]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:02<00:01,  1.16s/it, actor_loss=-.000116, critic_loss=0.000235]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:03<00:01,  1.16s/it, actor_loss=-.000343, critic_loss=0.0002]  \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it, actor_loss=-.000343, critic_loss=0.0002]\u001b[A\n",
      "Episode [2/10]: 100%|██████████| 3/3 [00:38<00:00, 12.68s/it]\n",
      "Episode [3/10]:  67%|██████▋   | 2/3 [00:21<00:10, 10.69s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:01<?, ?it/s, actor_loss=-.000455, critic_loss=0.00015]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:02,  1.16s/it, actor_loss=-.000455, critic_loss=0.00015]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:02<00:02,  1.16s/it, actor_loss=-.000335, critic_loss=0.000191]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:02<00:01,  1.17s/it, actor_loss=-.000335, critic_loss=0.000191]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:03<00:01,  1.17s/it, actor_loss=-.000308, critic_loss=0.000394]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it, actor_loss=-.000308, critic_loss=0.000394]\u001b[A\n",
      "Episode [3/10]: 100%|██████████| 3/3 [00:35<00:00, 11.98s/it]\n",
      "Episode [4/10]:  67%|██████▋   | 2/3 [00:22<00:11, 11.29s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:01<?, ?it/s, actor_loss=-.000577, critic_loss=0.000327]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:02,  1.16s/it, actor_loss=-.000577, critic_loss=0.000327]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:02<00:02,  1.16s/it, actor_loss=-.000642, critic_loss=0.000573]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:02<00:01,  1.17s/it, actor_loss=-.000642, critic_loss=0.000573]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:03<00:01,  1.17s/it, actor_loss=-.000672, critic_loss=0.00053] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it, actor_loss=-.000672, critic_loss=0.00053]\u001b[A\n",
      "Episode [4/10]: 100%|██████████| 3/3 [00:37<00:00, 12.55s/it]\n",
      "Episode [5/10]:  67%|██████▋   | 2/3 [00:22<00:11, 11.50s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:01<?, ?it/s, actor_loss=-.000958, critic_loss=0.000437]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:02,  1.17s/it, actor_loss=-.000958, critic_loss=0.000437]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:02<00:02,  1.17s/it, actor_loss=-.000831, critic_loss=0.000648]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:02<00:01,  1.16s/it, actor_loss=-.000831, critic_loss=0.000648]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:03<00:01,  1.16s/it, actor_loss=-.000904, critic_loss=0.00055] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it, actor_loss=-.000904, critic_loss=0.00055]\u001b[A\n",
      "Episode [5/10]: 100%|██████████| 3/3 [00:38<00:00, 12.68s/it]\n",
      "Episode [6/10]:  67%|██████▋   | 2/3 [00:22<00:11, 11.45s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:01<?, ?it/s, actor_loss=-.00112, critic_loss=0.00049]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:02,  1.17s/it, actor_loss=-.00112, critic_loss=0.00049]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:02<00:02,  1.17s/it, actor_loss=-.00123, critic_loss=0.000201]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:02<00:01,  1.17s/it, actor_loss=-.00123, critic_loss=0.000201]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:03<00:01,  1.17s/it, actor_loss=-.00118, critic_loss=0.000298]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it, actor_loss=-.00118, critic_loss=0.000298]\u001b[A\n",
      "Episode [6/10]: 100%|██████████| 3/3 [00:37<00:00, 12.67s/it]\n",
      "Episode [7/10]:  67%|██████▋   | 2/3 [00:23<00:11, 11.69s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:01<?, ?it/s, actor_loss=-.00127, critic_loss=0.000584]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:02,  1.15s/it, actor_loss=-.00127, critic_loss=0.000584]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:02<00:02,  1.15s/it, actor_loss=-.0015, critic_loss=0.000466] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:02<00:01,  1.16s/it, actor_loss=-.0015, critic_loss=0.000466]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:03<00:01,  1.16s/it, actor_loss=-.00132, critic_loss=0.000389]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it, actor_loss=-.00132, critic_loss=0.000389]\u001b[A\n",
      "Episode [7/10]: 100%|██████████| 3/3 [00:38<00:00, 12.73s/it]\n",
      "Episode [8/10]:  67%|██████▋   | 2/3 [00:22<00:11, 11.22s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:01<?, ?it/s, actor_loss=-.00173, critic_loss=0.000589]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:02,  1.16s/it, actor_loss=-.00173, critic_loss=0.000589]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:02<00:02,  1.16s/it, actor_loss=-.00177, critic_loss=0.000847]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:02<00:01,  1.16s/it, actor_loss=-.00177, critic_loss=0.000847]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:03<00:01,  1.16s/it, actor_loss=-.0016, critic_loss=0.000703] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it, actor_loss=-.0016, critic_loss=0.000703]\u001b[A\n",
      "Episode [8/10]: 100%|██████████| 3/3 [00:37<00:00, 12.46s/it]\n",
      "Episode [9/10]:  67%|██████▋   | 2/3 [00:22<00:11, 11.42s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:01<?, ?it/s, actor_loss=-.00181, critic_loss=0.00019]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:02,  1.16s/it, actor_loss=-.00181, critic_loss=0.00019]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:02<00:02,  1.16s/it, actor_loss=-.00191, critic_loss=0.000368]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:02<00:01,  1.17s/it, actor_loss=-.00191, critic_loss=0.000368]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:03<00:01,  1.17s/it, actor_loss=-.00205, critic_loss=0.000343]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it, actor_loss=-.00205, critic_loss=0.000343]\u001b[A\n",
      "Episode [9/10]: 100%|██████████| 3/3 [00:37<00:00, 12.55s/it]\n",
      "Episode [10/10]:  67%|██████▋   | 2/3 [00:22<00:11, 11.31s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:01<?, ?it/s, actor_loss=-.00231, critic_loss=0.000598]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:02,  1.17s/it, actor_loss=-.00231, critic_loss=0.000598]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:02<00:02,  1.17s/it, actor_loss=-.00199, critic_loss=0.000616]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:02<00:01,  1.17s/it, actor_loss=-.00199, critic_loss=0.000616]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:03<00:01,  1.17s/it, actor_loss=-.00231, critic_loss=0.000172]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it, actor_loss=-.00231, critic_loss=0.000172]\u001b[A\n",
      "Episode [10/10]: 100%|██████████| 3/3 [00:37<00:00, 12.56s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "actor.model.save_pretrained(f'./model/{save_dir}/output_3_PPO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f8e943",
   "metadata": {},
   "source": [
    "### RLHF가 적용된 custom chatgpt의 생성능력을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "442706f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'네, 불고용 고기 한우와 마찬가지로 한우에도 사용됩니다. \\n\\n해당 문장에서 \"불고기용 고기 한우\"는 어떤 한우를 가리키는지 명확하지 않아 정확한 답변을 제공할 수 없습니다. 좀 더 구체적인 문맥이 있으면 도움을 드릴 수 있을 것 같습니다. \\n\\n해당 문장에서는 'one can eat on a gimpang of korea'로 번역되었는데, 이는 어떤 지역의 것을 가리키는 것인지 명확하지 않습니다. 정확한 문맥이 필요합니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'1971년이다. \\n\\n그러나, \"42\" 년도\"가 1944년으로 표기되어 있어 정확한 시간은 정확히 나오지 않았습니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어\n",
      "\n",
      "### Response(응답):'시카고 오헤어 국제공항은 미국 뉴저지주 오헤어(ORO) 오헤어(Offenburg) 현지에 위치해 있습니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'저는 인공지능 언어모델로 대답하고 있어서 미세먼지 농도를 확인할 수 없지만, 보통 미세먼지 농도는 보통 5-11월이 가장 높아요. 그러므로 봄이 오기 전에 미리 예방하기 위해서는 미세먼지 예보를 확인하는 것이 중요합니다. 또한 외출 후에는 마스크를 착용하고, 먼지를 줄일 수 있는 실내 공기를 충분히 배치하는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print()\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "\n",
    "for input_text in list_prompt:\n",
    "    output = generation(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c1fa17",
   "metadata": {},
   "source": [
    "#### 메모리 관리를 위해 캐시를 비우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "704bcc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb5aba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
